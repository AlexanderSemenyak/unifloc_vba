''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'ARGONNE NATIONAL LABORATORY. MINPACK PROJECT. JUNE 1983
'JORGE J. MORE', DAVID J. THUENTE
'
'>>> SOURCE LICENSE >>>
'This program is free software; you can redistribute it and/or modify
'it under the terms of the GNU General Public License as published by
'the Free Software Foundation (www.fsf.org); either version 2 of the
'License, or (at your option) any later version.
'
'This program is distributed in the hope that it will be useful,
'but WITHOUT ANY WARRANTY; without even the implied warranty of
'MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
'GNU General Public License for more details.
'
'A copy of the GNU General Public License is available at
'http://www.fsf.org/licensing/licenses
'
'>>> END OF LICENSE >>>
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Data types
Public Type LINMINState
    BRACKT As Boolean
    STAGE1 As Boolean
    INFOC As Long
    DG As Double
    DGM As Double
    DGInit As Double
    DGTEST As Double
    DGX As Double
    DGXM As Double
    DGY As Double
    DGYM As Double
    FInit As Double
    FTEST1 As Double
    FM As Double
    FX As Double
    FXM As Double
    FY As Double
    FYM As Double
    STX As Double
    STY As Double
    STMIN As Double
    STMAX As Double
    WIDTH As Double
    WIDTH1 As Double
    XTRAPF As Double
End Type
'Global constants
Private Const FTOL As Double = 0.001
Private Const XTOL As Double = 100# * MachineEpsilon
Private Const GTOL As Double = 0.3
Private Const MAXFEV As Long = 20#
Private Const STPMIN As Double = 1E-50
Private Const DefSTPMAX As Double = 1E+50
'Data types
Public Type MinASAState
    N As Long
    EpsG As Double
    EpsF As Double
    EpsX As Double
    MaxIts As Long
    XRep As Boolean
    StpMax As Double
    CGType As Long
    K As Long
    NFEV As Long
    MCStage As Long
    BndL() As Double
    BndU() As Double
    CurAlgo As Long
    ACount As Long
    Mu As Double
    FInit As Double
    DGInit As Double
    AK() As Double
    XK() As Double
    DK() As Double
    AN() As Double
    XN() As Double
    DN() As Double
    D() As Double
    Fold As Double
    Stp As Double
    WORK() As Double
    YK() As Double
    GC() As Double
    X() As Double
    F As Double
    G() As Double
    NeedFG As Boolean
    XUpdated As Boolean
    RState As RCommState
    RepIterationsCount As Long
    RepNFEV As Long
    RepTerminationType As Long
    DebugRestartsCount As Long
    LState As LINMINState
    BetaHS As Double
    BetaDY As Double
End Type
Public Type MinASAReport
    IterationsCount As Long
    NFEV As Long
    TerminationType As Long
    ActiveConstraints As Long
End Type
'Global constants
Private Const N1 As Long = 2#
Private Const N2 As Long = 2#
'Private Const STPMIN As Double = 1E-300
Private Const GPAFTol As Double = 0.0001
Private Const GPADecay As Double = 0.5
Private Const ASARho As Double = 0.5
'Data types
Public Type MinCGState
    N As Long
    EpsG As Double
    EpsF As Double
    EpsX As Double
    MaxIts As Long
    StpMax As Double
    XRep As Boolean
    CGType As Long
    NFEV As Long
    MCStage As Long
    K As Long
    XK() As Double
    DK() As Double
    XN() As Double
    DN() As Double
    D() As Double
    Fold As Double
    Stp As Double
    WORK() As Double
    YK() As Double
    X() As Double
    F As Double
    G() As Double
    NeedFG As Boolean
    XUpdated As Boolean
    RState As RCommState
    RepIterationsCount As Long
    RepNFEV As Long
    RepTerminationType As Long
    DebugRestartsCount As Long
    LState As LINMINState
    BetaHS As Double
    BetaDY As Double
End Type
Public Type MinCGReport
    IterationsCount As Long
    NFEV As Long
    TerminationType As Long
End Type
'Data types
Public Type MinLBFGSState
    N As Long
    M As Long
    EpsG As Double
    EpsF As Double
    EpsX As Double
    MaxIts As Long
    Flags As Long
    XRep As Boolean
    StpMax As Double
    NFEV As Long
    MCStage As Long
    K As Long
    q As Long
    p As Long
    Rho() As Double
    y() As Double
    S() As Double
    Theta() As Double
    D() As Double
    Stp As Double
    WORK() As Double
    Fold As Double
    GammaK As Double
    X() As Double
    F As Double
    G() As Double
    NeedFG As Boolean
    XUpdated As Boolean
    RState As RCommState
    RepIterationsCount As Long
    RepNFEV As Long
    RepTerminationType As Long
    LState As LINMINState
End Type
Public Type MinLBFGSReport
    IterationsCount As Long
    NFEV As Long
    TerminationType As Long
End Type
'Data types
Public Type MinLMState
    WrongParams As Boolean
    N As Long
    M As Long
    EpsG As Double
    EpsF As Double
    EpsX As Double
    MaxIts As Long
    XRep As Boolean
    StpMax As Double
    Flags As Long
    UserMode As Long
    X() As Double
    F As Double
    FI() As Double
    j() As Double
    H() As Double
    G() As Double
    NeedF As Boolean
    NeedFG As Boolean
    NeedFGH As Boolean
    NeedFiJ As Boolean
    XUpdated As Boolean
    InternalState As MinLBFGSState
    InternalRep As MinLBFGSReport
    XPrec() As Double
    XBase() As Double
    XDir() As Double
    GBase() As Double
    XPrev() As Double
    FPrev As Double
    RawModel() As Double
    Model() As Double
    WORK() As Double
    RState As RCommState
    RepIterationsCount As Long
    RepTerminationType As Long
    RepNFunc As Long
    RepNJac As Long
    RepNGrad As Long
    RepNHess As Long
    RepNCholesky As Long
    SolverInfo As Long
    SolverRep As DenseSolverReport
    InvInfo As Long
    InvRep As MatInvReport
End Type
Public Type MinLMReport
    IterationsCount As Long
    TerminationType As Long
    NFunc As Long
    NJac As Long
    NGrad As Long
    NHess As Long
    NCholesky As Long
End Type
'Global constants
Private Const LMModeFJ As Long = 0#
Private Const LMModeFGJ As Long = 1#
Private Const LMModeFGH As Long = 2#
Private Const LMFlagNoPreLBFGS As Long = 1#
Private Const LMFlagNoIntLBFGS As Long = 2#
Private Const LMPreLBFGSM As Long = 5#
Private Const LMIntLBFGSIts As Long = 5#
Private Const LBFGSNoRealloc As Long = 1#
'Routines
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Normalizes direction/step pair: makes |D|=1, scales Stp.
'If |D|=0, it returns, leavind D/Stp unchanged.
'
'  -- ALGLIB --
'     Copyright 01.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub LinMinNormalizeD(ByRef D() As Double, _
         ByRef Stp As Double, _
         ByVal N As Long)
    Dim MX As Double
    Dim S As Double
    Dim i As Long
    Dim i_ As Long
    
    '
    ' first, scale D to avoid underflow/overflow durng squaring
    '
    MX = 0#
    For i = 0# To N - 1# Step 1
        MX = MaxReal(MX, Abs(D(i)))
    Next i
    If MX = 0# Then
        Exit Sub
    End If
    S = 1# / MX
    For i_ = 0# To N - 1# Step 1
        D(i_) = S * D(i_)
    Next i_
    Stp = Stp / S
    
    '
    ' normalize D
    '
    S = 0#
    For i_ = 0# To N - 1# Step 1
        S = S + D(i_) * D(i_)
    Next i_
    S = 1# / Sqr(S)
    For i_ = 0# To N - 1# Step 1
        D(i_) = S * D(i_)
    Next i_
    Stp = Stp / S
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'THE  PURPOSE  OF  MCSRCH  IS  TO  FIND A STEP WHICH SATISFIES A SUFFICIENT
'DECREASE CONDITION AND A CURVATURE CONDITION.
'
'AT EACH STAGE THE SUBROUTINE  UPDATES  AN  INTERVAL  OF  UNCERTAINTY  WITH
'ENDPOINTS  STX  AND  STY.  THE INTERVAL OF UNCERTAINTY IS INITIALLY CHOSEN
'SO THAT IT CONTAINS A MINIMIZER OF THE MODIFIED FUNCTION
'
'    F(X+STP*S) - F(X) - FTOL*STP*(GRADF(X)'S).
'
'IF  A STEP  IS OBTAINED FOR  WHICH THE MODIFIED FUNCTION HAS A NONPOSITIVE
'FUNCTION  VALUE  AND  NONNEGATIVE  DERIVATIVE,   THEN   THE   INTERVAL  OF
'UNCERTAINTY IS CHOSEN SO THAT IT CONTAINS A MINIMIZER OF F(X+STP*S).
'
'THE  ALGORITHM  IS  DESIGNED TO FIND A STEP WHICH SATISFIES THE SUFFICIENT
'DECREASE CONDITION
'
'    F(X+STP*S) .LE. F(X) + FTOL*STP*(GRADF(X)'S),
'
'AND THE CURVATURE CONDITION
'
'    ABS(GRADF(X+STP*S)'S)) .LE. GTOL*ABS(GRADF(X)'S).
'
'IF  FTOL  IS  LESS  THAN GTOL AND IF, FOR EXAMPLE, THE FUNCTION IS BOUNDED
'BELOW,  THEN  THERE  IS  ALWAYS  A  STEP  WHICH SATISFIES BOTH CONDITIONS.
'IF  NO  STEP  CAN BE FOUND  WHICH  SATISFIES  BOTH  CONDITIONS,  THEN  THE
'ALGORITHM  USUALLY STOPS  WHEN  ROUNDING ERRORS  PREVENT FURTHER PROGRESS.
'IN THIS CASE STP ONLY SATISFIES THE SUFFICIENT DECREASE CONDITION.
'
'PARAMETERS DESCRIPRION
'
'N IS A POSITIVE INTEGER INPUT VARIABLE SET TO THE NUMBER OF VARIABLES.
'
'X IS  AN  ARRAY  OF  LENGTH N. ON INPUT IT MUST CONTAIN THE BASE POINT FOR
'THE LINE SEARCH. ON OUTPUT IT CONTAINS X+STP*S.
'
'F IS  A  VARIABLE. ON INPUT IT MUST CONTAIN THE VALUE OF F AT X. ON OUTPUT
'IT CONTAINS THE VALUE OF F AT X + STP*S.
'
'G IS AN ARRAY OF LENGTH N. ON INPUT IT MUST CONTAIN THE GRADIENT OF F AT X.
'ON OUTPUT IT CONTAINS THE GRADIENT OF F AT X + STP*S.
'
'S IS AN INPUT ARRAY OF LENGTH N WHICH SPECIFIES THE SEARCH DIRECTION.
'
'STP  IS  A NONNEGATIVE VARIABLE. ON INPUT STP CONTAINS AN INITIAL ESTIMATE
'OF A SATISFACTORY STEP. ON OUTPUT STP CONTAINS THE FINAL ESTIMATE.
'
'FTOL AND GTOL ARE NONNEGATIVE INPUT VARIABLES. TERMINATION OCCURS WHEN THE
'SUFFICIENT DECREASE CONDITION AND THE DIRECTIONAL DERIVATIVE CONDITION ARE
'SATISFIED.
'
'XTOL IS A NONNEGATIVE INPUT VARIABLE. TERMINATION OCCURS WHEN THE RELATIVE
'WIDTH OF THE INTERVAL OF UNCERTAINTY IS AT MOST XTOL.
'
'STPMIN AND STPMAX ARE NONNEGATIVE INPUT VARIABLES WHICH SPECIFY LOWER  AND
'UPPER BOUNDS FOR THE STEP.
'
'MAXFEV IS A POSITIVE INTEGER INPUT VARIABLE. TERMINATION OCCURS WHEN THE
'NUMBER OF CALLS TO FCN IS AT LEAST MAXFEV BY THE END OF AN ITERATION.
'
'INFO IS AN INTEGER OUTPUT VARIABLE SET AS FOLLOWS:
'    INFO = 0  IMPROPER INPUT PARAMETERS.
'
'    INFO = 1  THE SUFFICIENT DECREASE CONDITION AND THE
'              DIRECTIONAL DERIVATIVE CONDITION HOLD.
'
'    INFO = 2  RELATIVE WIDTH OF THE INTERVAL OF UNCERTAINTY
'              IS AT MOST XTOL.
'
'    INFO = 3  NUMBER OF CALLS TO FCN HAS REACHED MAXFEV.
'
'    INFO = 4  THE STEP IS AT THE LOWER BOUND STPMIN.
'
'    INFO = 5  THE STEP IS AT THE UPPER BOUND STPMAX.
'
'    INFO = 6  ROUNDING ERRORS PREVENT FURTHER PROGRESS.
'              THERE MAY NOT BE A STEP WHICH SATISFIES THE
'              SUFFICIENT DECREASE AND CURVATURE CONDITIONS.
'              TOLERANCES MAY BE TOO SMALL.
'
'NFEV IS AN INTEGER OUTPUT VARIABLE SET TO THE NUMBER OF CALLS TO FCN.
'
'WA IS A WORK ARRAY OF LENGTH N.
'
'ARGONNE NATIONAL LABORATORY. MINPACK PROJECT. JUNE 1983
'JORGE J. MORE', DAVID J. THUENTE
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MCSRCH(ByRef N As Long, _
         ByRef X() As Double, _
         ByRef F As Double, _
         ByRef G() As Double, _
         ByRef S() As Double, _
         ByRef Stp As Double, _
         ByVal StpMax As Double, _
         ByRef Info As Long, _
         ByRef NFEV As Long, _
         ByRef WA() As Double, _
         ByRef State As LINMINState, _
         ByRef Stage As Long)
    Dim V As Double
    Dim P5 As Double
    Dim P66 As Double
    Dim ZERO As Double
    Dim i_ As Long
    
    '
    ' init
    '
    P5 = 0.5
    P66 = 0.66
    State.XTRAPF = 4#
    ZERO = 0#
    If StpMax = 0# Then
        StpMax = DefSTPMAX
    End If
    If Stp < STPMIN Then
        Stp = STPMIN
    End If
    If Stp > StpMax Then
        Stp = StpMax
    End If
    
    '
    ' Main cycle
    '
    Do While True
        If Stage = 0# Then
            
            '
            ' NEXT
            '
            Stage = 2#
            GoTo Cont_1
        End If
        If Stage = 2# Then
            State.INFOC = 1#
            Info = 0#
            
            '
            '     CHECK THE INPUT PARAMETERS FOR ERRORS.
            '
            If N <= 0# Or Stp <= 0# Or FTOL < 0# Or GTOL < ZERO Or XTOL < ZERO Or STPMIN < ZERO Or StpMax < STPMIN Or MAXFEV <= 0# Then
                Stage = 0#
                Exit Sub
            End If
            
            '
            '     COMPUTE THE INITIAL GRADIENT IN THE SEARCH DIRECTION
            '     AND CHECK THAT S IS A DESCENT DIRECTION.
            '
            V = 0#
            For i_ = 0# To N - 1# Step 1
                V = V + G(i_) * S(i_)
            Next i_
            State.DGInit = V
            If State.DGInit >= 0# Then
                Stage = 0#
                Exit Sub
            End If
            
            '
            '     INITIALIZE LOCAL VARIABLES.
            '
            State.BRACKT = False
            State.STAGE1 = True
            NFEV = 0#
            State.FInit = F
            State.DGTEST = FTOL * State.DGInit
            State.WIDTH = StpMax - STPMIN
            State.WIDTH1 = State.WIDTH / P5
            For i_ = 0# To N - 1# Step 1
                WA(i_) = X(i_)
            Next i_
            
            '
            '     THE VARIABLES STX, FX, DGX CONTAIN THE VALUES OF THE STEP,
            '     FUNCTION, AND DIRECTIONAL DERIVATIVE AT THE BEST STEP.
            '     THE VARIABLES STY, FY, DGY CONTAIN THE VALUE OF THE STEP,
            '     FUNCTION, AND DERIVATIVE AT THE OTHER ENDPOINT OF
            '     THE INTERVAL OF UNCERTAINTY.
            '     THE VARIABLES STP, F, DG CONTAIN THE VALUES OF THE STEP,
            '     FUNCTION, AND DERIVATIVE AT THE CURRENT STEP.
            '
            State.STX = 0#
            State.FX = State.FInit
            State.DGX = State.DGInit
            State.STY = 0#
            State.FY = State.FInit
            State.DGY = State.DGInit
            
            '
            ' NEXT
            '
            Stage = 3#
            GoTo Cont_1
        End If
        If Stage = 3# Then
            
            '
            '     START OF ITERATION.
            '
            '     SET THE MINIMUM AND MAXIMUM STEPS TO CORRESPOND
            '     TO THE PRESENT INTERVAL OF UNCERTAINTY.
            '
            If State.BRACKT Then
                If State.STX < State.STY Then
                    State.STMIN = State.STX
                    State.STMAX = State.STY
                Else
                    State.STMIN = State.STY
                    State.STMAX = State.STX
                End If
            Else
                State.STMIN = State.STX
                State.STMAX = Stp + State.XTRAPF * (Stp - State.STX)
            End If
            
            '
            '        FORCE THE STEP TO BE WITHIN THE BOUNDS STPMAX AND STPMIN.
            '
            If Stp > StpMax Then
                Stp = StpMax
            End If
            If Stp < STPMIN Then
                Stp = STPMIN
            End If
            
            '
            '        IF AN UNUSUAL TERMINATION IS TO OCCUR THEN LET
            '        STP BE THE LOWEST POINT OBTAINED SO FAR.
            '
            If State.BRACKT And (Stp <= State.STMIN Or Stp >= State.STMAX) Or NFEV >= MAXFEV - 1# Or State.INFOC = 0# Or State.BRACKT And State.STMAX - State.STMIN <= XTOL * State.STMAX Then
                Stp = State.STX
            End If
            
            '
            '        EVALUATE THE FUNCTION AND GRADIENT AT STP
            '        AND COMPUTE THE DIRECTIONAL DERIVATIVE.
            '
            For i_ = 0# To N - 1# Step 1
                X(i_) = WA(i_)
            Next i_
            For i_ = 0# To N - 1# Step 1
                X(i_) = X(i_) + Stp * S(i_)
            Next i_
            
            '
            ' NEXT
            '
            Stage = 4#
            Exit Sub
        End If
        If Stage = 4# Then
            Info = 0#
            NFEV = NFEV + 1#
            V = 0#
            For i_ = 0# To N - 1# Step 1
                V = V + G(i_) * S(i_)
            Next i_
            State.DG = V
            State.FTEST1 = State.FInit + Stp * State.DGTEST
            
            '
            '        TEST FOR CONVERGENCE.
            '
            If State.BRACKT And (Stp <= State.STMIN Or Stp >= State.STMAX) Or State.INFOC = 0# Then
                Info = 6#
            End If
            If Stp = StpMax And F <= State.FTEST1 And State.DG <= State.DGTEST Then
                Info = 5#
            End If
            If Stp = STPMIN And (F > State.FTEST1 Or State.DG >= State.DGTEST) Then
                Info = 4#
            End If
            If NFEV >= MAXFEV Then
                Info = 3#
            End If
            If State.BRACKT And State.STMAX - State.STMIN <= XTOL * State.STMAX Then
                Info = 2#
            End If
            If F <= State.FTEST1 And Abs(State.DG) <= -(GTOL * State.DGInit) Then
                Info = 1#
            End If
            
            '
            '        CHECK FOR TERMINATION.
            '
            If Info <> 0# Then
                Stage = 0#
                Exit Sub
            End If
            
            '
            '        IN THE FIRST STAGE WE SEEK A STEP FOR WHICH THE MODIFIED
            '        FUNCTION HAS A NONPOSITIVE VALUE AND NONNEGATIVE DERIVATIVE.
            '
            If State.STAGE1 And F <= State.FTEST1 And State.DG >= MinReal(FTOL, GTOL) * State.DGInit Then
                State.STAGE1 = False
            End If
            
            '
            '        A MODIFIED FUNCTION IS USED TO PREDICT THE STEP ONLY IF
            '        WE HAVE NOT OBTAINED A STEP FOR WHICH THE MODIFIED
            '        FUNCTION HAS A NONPOSITIVE FUNCTION VALUE AND NONNEGATIVE
            '        DERIVATIVE, AND IF A LOWER FUNCTION VALUE HAS BEEN
            '        OBTAINED BUT THE DECREASE IS NOT SUFFICIENT.
            '
            If State.STAGE1 And F <= State.FX And F > State.FTEST1 Then
                
                '
                '           DEFINE THE MODIFIED FUNCTION AND DERIVATIVE VALUES.
                '
                State.FM = F - Stp * State.DGTEST
                State.FXM = State.FX - State.STX * State.DGTEST
                State.FYM = State.FY - State.STY * State.DGTEST
                State.DGM = State.DG - State.DGTEST
                State.DGXM = State.DGX - State.DGTEST
                State.DGYM = State.DGY - State.DGTEST
                
                '
                '           CALL CSTEP TO UPDATE THE INTERVAL OF UNCERTAINTY
                '           AND TO COMPUTE THE NEW STEP.
                '
                Call MCSTEP(State.STX, State.FXM, State.DGXM, State.STY, State.FYM, State.DGYM, Stp, State.FM, State.DGM, State.BRACKT, State.STMIN, State.STMAX, State.INFOC)
                
                '
                '           RESET THE FUNCTION AND GRADIENT VALUES FOR F.
                '
                State.FX = State.FXM + State.STX * State.DGTEST
                State.FY = State.FYM + State.STY * State.DGTEST
                State.DGX = State.DGXM + State.DGTEST
                State.DGY = State.DGYM + State.DGTEST
            Else
                
                '
                '           CALL MCSTEP TO UPDATE THE INTERVAL OF UNCERTAINTY
                '           AND TO COMPUTE THE NEW STEP.
                '
                Call MCSTEP(State.STX, State.FX, State.DGX, State.STY, State.FY, State.DGY, Stp, F, State.DG, State.BRACKT, State.STMIN, State.STMAX, State.INFOC)
            End If
            
            '
            '        FORCE A SUFFICIENT DECREASE IN THE SIZE OF THE
            '        INTERVAL OF UNCERTAINTY.
            '
            If State.BRACKT Then
                If Abs(State.STY - State.STX) >= P66 * State.WIDTH1 Then
                    Stp = State.STX + P5 * (State.STY - State.STX)
                End If
                State.WIDTH1 = State.WIDTH
                State.WIDTH = Abs(State.STY - State.STX)
            End If
            
            '
            '  NEXT.
            '
            Stage = 3#
            GoTo Cont_1
        End If
Cont_1:
    Loop
End Sub
Private Sub MCSTEP(ByRef STX As Double, _
         ByRef FX As Double, _
         ByRef DX As Double, _
         ByRef STY As Double, _
         ByRef FY As Double, _
         ByRef DY As Double, _
         ByRef Stp As Double, _
         ByRef FP As Double, _
         ByRef DP As Double, _
         ByRef BRACKT As Boolean, _
         ByRef STMIN As Double, _
         ByRef STMAX As Double, _
         ByRef Info As Long)
    Dim BOUND As Boolean
    Dim Gamma As Double
    Dim p As Double
    Dim q As Double
    Dim R As Double
    Dim S As Double
    Dim SGND As Double
    Dim STPC As Double
    Dim STPF As Double
    Dim STPQ As Double
    Dim Theta As Double
    Info = 0#
    
    '
    '     CHECK THE INPUT PARAMETERS FOR ERRORS.
    '
    If BRACKT And (Stp <= MinReal(STX, STY) Or Stp >= MaxReal(STX, STY)) Or DX * (Stp - STX) >= 0# Or STMAX < STMIN Then
        Exit Sub
    End If
    
    '
    '     DETERMINE IF THE DERIVATIVES HAVE OPPOSITE SIGN.
    '
    SGND = DP * (DX / Abs(DX))
    
    '
    '     FIRST CASE. A HIGHER FUNCTION VALUE.
    '     THE MINIMUM IS BRACKETED. IF THE CUBIC STEP IS CLOSER
    '     TO STX THAN THE QUADRATIC STEP, THE CUBIC STEP IS TAKEN,
    '     ELSE THE AVERAGE OF THE CUBIC AND QUADRATIC STEPS IS TAKEN.
    '
    If FP > FX Then
        Info = 1#
        BOUND = True
        Theta = 3# * (FX - FP) / (Stp - STX) + DX + DP
        S = MaxReal(Abs(Theta), MaxReal(Abs(DX), Abs(DP)))
        Gamma = S * Sqr(Square(Theta / S) - DX / S * (DP / S))
        If Stp < STX Then
            Gamma = -Gamma
        End If
        p = Gamma - DX + Theta
        q = Gamma - DX + Gamma + DP
        R = p / q
        STPC = STX + R * (Stp - STX)
        STPQ = STX + DX / ((FX - FP) / (Stp - STX) + DX) / 2# * (Stp - STX)
        If Abs(STPC - STX) < Abs(STPQ - STX) Then
            STPF = STPC
        Else
            STPF = STPC + (STPQ - STPC) / 2#
        End If
        BRACKT = True
    Else
        If SGND < 0# Then
            
            '
            '     SECOND CASE. A LOWER FUNCTION VALUE AND DERIVATIVES OF
            '     OPPOSITE SIGN. THE MINIMUM IS BRACKETED. IF THE CUBIC
            '     STEP IS CLOSER TO STX THAN THE QUADRATIC (SECANT) STEP,
            '     THE CUBIC STEP IS TAKEN, ELSE THE QUADRATIC STEP IS TAKEN.
            '
            Info = 2#
            BOUND = False
            Theta = 3# * (FX - FP) / (Stp - STX) + DX + DP
            S = MaxReal(Abs(Theta), MaxReal(Abs(DX), Abs(DP)))
            Gamma = S * Sqr(Square(Theta / S) - DX / S * (DP / S))
            If Stp > STX Then
                Gamma = -Gamma
            End If
            p = Gamma - DP + Theta
            q = Gamma - DP + Gamma + DX
            R = p / q
            STPC = Stp + R * (STX - Stp)
            STPQ = Stp + DP / (DP - DX) * (STX - Stp)
            If Abs(STPC - Stp) > Abs(STPQ - Stp) Then
                STPF = STPC
            Else
                STPF = STPQ
            End If
            BRACKT = True
        Else
            If Abs(DP) < Abs(DX) Then
                
                '
                '     THIRD CASE. A LOWER FUNCTION VALUE, DERIVATIVES OF THE
                '     SAME SIGN, AND THE MAGNITUDE OF THE DERIVATIVE DECREASES.
                '     THE CUBIC STEP IS ONLY USED IF THE CUBIC TENDS TO INFINITY
                '     IN THE DIRECTION OF THE STEP OR IF THE MINIMUM OF THE CUBIC
                '     IS BEYOND STP. OTHERWISE THE CUBIC STEP IS DEFINED TO BE
                '     EITHER STPMIN OR STPMAX. THE QUADRATIC (SECANT) STEP IS ALSO
                '     COMPUTED AND IF THE MINIMUM IS BRACKETED THEN THE THE STEP
                '     CLOSEST TO STX IS TAKEN, ELSE THE STEP FARTHEST AWAY IS TAKEN.
                '
                Info = 3#
                BOUND = True
                Theta = 3# * (FX - FP) / (Stp - STX) + DX + DP
                S = MaxReal(Abs(Theta), MaxReal(Abs(DX), Abs(DP)))
                
                '
                '        THE CASE GAMMA = 0 ONLY ARISES IF THE CUBIC DOES NOT TEND
                '        TO INFINITY IN THE DIRECTION OF THE STEP.
                '
                Gamma = S * Sqr(MaxReal(0#, Square(Theta / S) - DX / S * (DP / S)))
                If Stp > STX Then
                    Gamma = -Gamma
                End If
                p = Gamma - DP + Theta
                q = Gamma + (DX - DP) + Gamma
                R = p / q
                If R < 0# And Gamma <> 0# Then
                    STPC = Stp + R * (STX - Stp)
                Else
                    If Stp > STX Then
                        STPC = STMAX
                    Else
                        STPC = STMIN
                    End If
                End If
                STPQ = Stp + DP / (DP - DX) * (STX - Stp)
                If BRACKT Then
                    If Abs(Stp - STPC) < Abs(Stp - STPQ) Then
                        STPF = STPC
                    Else
                        STPF = STPQ
                    End If
                Else
                    If Abs(Stp - STPC) > Abs(Stp - STPQ) Then
                        STPF = STPC
                    Else
                        STPF = STPQ
                    End If
                End If
            Else
                
                '
                '     FOURTH CASE. A LOWER FUNCTION VALUE, DERIVATIVES OF THE
                '     SAME SIGN, AND THE MAGNITUDE OF THE DERIVATIVE DOES
                '     NOT DECREASE. IF THE MINIMUM IS NOT BRACKETED, THE STEP
                '     IS EITHER STPMIN OR STPMAX, ELSE THE CUBIC STEP IS TAKEN.
                '
                Info = 4#
                BOUND = False
                If BRACKT Then
                    Theta = 3# * (FP - FY) / (STY - Stp) + DY + DP
                    S = MaxReal(Abs(Theta), MaxReal(Abs(DY), Abs(DP)))
                    Gamma = S * Sqr(Square(Theta / S) - DY / S * (DP / S))
                    If Stp > STY Then
                        Gamma = -Gamma
                    End If
                    p = Gamma - DP + Theta
                    q = Gamma - DP + Gamma + DY
                    R = p / q
                    STPC = Stp + R * (STY - Stp)
                    STPF = STPC
                Else
                    If Stp > STX Then
                        STPF = STMAX
                    Else
                        STPF = STMIN
                    End If
                End If
            End If
        End If
    End If
    
    '
    '     UPDATE THE INTERVAL OF UNCERTAINTY. THIS UPDATE DOES NOT
    '     DEPEND ON THE NEW STEP OR THE CASE ANALYSIS ABOVE.
    '
    If FP > FX Then
        STY = Stp
        FY = FP
        DY = DP
    Else
        If SGND < 0# Then
            STY = STX
            FY = FX
            DY = DX
        End If
        STX = Stp
        FX = FP
        DX = DP
    End If
    
    '
    '     COMPUTE THE NEW STEP AND SAFEGUARD IT.
    '
    STPF = MinReal(STMAX, STPF)
    STPF = MaxReal(STMIN, STPF)
    Stp = STPF
    If BRACKT And BOUND Then
        If STY > STX Then
            Stp = MinReal(STX + 0.66 * (STY - STX), Stp)
        Else
            Stp = MaxReal(STX + 0.66 * (STY - STX), Stp)
        End If
    End If
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Copyright (c) 2010, Sergey Bochkanov (ALGLIB project).
'
'>>> SOURCE LICENSE >>>
'This program is free software; you can redistribute it and/or modify
'it under the terms of the GNU General Public License as published by
'the Free Software Foundation (www.fsf.org); either version 2 of the
'License, or (at your option) any later version.
'
'This program is distributed in the hope that it will be useful,
'but WITHOUT ANY WARRANTY; without even the implied warranty of
'MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
'GNU General Public License for more details.
'
'A copy of the GNU General Public License is available at
'http://www.fsf.org/licensing/licenses
'
'>>> END OF LICENSE >>>
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Routines
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'              NONLINEAR BOUND CONSTRAINED OPTIMIZATION USING
'                               MODIFIED
'                   WILLIAM W. HAGER AND HONGCHAO ZHANG
'                         ACTIVE SET ALGORITHM
'
'The  subroutine  minimizes  function  F(x)  of  N  arguments  with   bound
'constraints: BndL[i] <= x[i] <= BndU[i]
'
'This method is  globally  convergent  as  long  as  grad(f)  is  Lipschitz
'continuous on a level set: L = { x : f(x)<=f(x0) }.
'
'INPUT PARAMETERS:
'    N       -   problem dimension. N>0
'    X       -   initial solution approximation, array[0..N-1].
'    BndL    -   lower bounds, array[0..N-1].
'                all elements MUST be specified,  i.e.  all  variables  are
'                bounded. However, if some (all) variables  are  unbounded,
'                you may specify very small number as bound: -1000,  -1.0E6
'                or -1.0E300, or something like that.
'    BndU    -   upper bounds, array[0..N-1].
'                all elements MUST be specified,  i.e.  all  variables  are
'                bounded. However, if some (all) variables  are  unbounded,
'                you may specify very large number as bound: +1000,  +1.0E6
'                or +1.0E300, or something like that.
'    EpsG    -   positive number which  defines  a  precision  of  search.  The
'                subroutine finishes its work if the condition ||G|| < EpsG  is
'                satisfied, where ||.|| means Euclidian norm, G - gradient, X -
'                current approximation.
'    EpsF    -   positive number which  defines  a  precision  of  search.  The
'                subroutine finishes its work if on iteration  number  k+1  the
'                condition |F(k+1)-F(k)| <= EpsF*max{|F(k)|, |F(k+1)|, 1}    is
'                satisfied.
'    EpsX    -   positive number which  defines  a  precision  of  search.  The
'                subroutine finishes its work if on iteration number k+1    the
'                condition |X(k+1)-X(k)| <= EpsX is fulfilled.
'    MaxIts  -   maximum number of iterations. If MaxIts=0, the number of
'                iterations is unlimited.
'
'OUTPUT PARAMETERS:
'    State - structure used for reverse communication.
'
'This function  initializes  State   structure  with  default  optimization
'parameters (stopping conditions, step size, etc.).  Use  MinASASet??????()
'functions to tune optimization parameters.
'
'After   all   optimization   parameters   are   tuned,   you   should  use
'MinASAIteration() function to advance algorithm iterations.
'
'NOTES:
'
'1. you may tune stopping conditions with MinASASetCond() function
'2. if target function contains exp() or other fast growing functions,  and
'   optimization algorithm makes too large steps which leads  to  overflow,
'   use MinASASetStpMax() function to bound algorithm's steps.
'
'  -- ALGLIB --
'     Copyright 25.03.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinASACreate(ByVal N As Long, _
         ByRef X() As Double, _
         ByRef BndL() As Double, _
         ByRef BndU() As Double, _
         ByRef State As MinASAState)
    Dim i As Long
    Dim i_ As Long
    For i = 0# To N - 1# Step 1
    Next i
    
    '
    ' Initialize
    '
    State.N = N
    Call MinASASetCond(State, 0#, 0#, 0#, 0#)
    Call MinASASetXRep(State, False)
    Call MinASASetStpMax(State, 0#)
    Call MinASASetAlgorithm(State, -1#)
    ReDim State.BndL(0 To N - 1)
    ReDim State.BndU(0 To N - 1)
    ReDim State.AK(0 To N - 1)
    ReDim State.XK(0 To N - 1)
    ReDim State.DK(0 To N - 1)
    ReDim State.AN(0 To N - 1)
    ReDim State.XN(0 To N - 1)
    ReDim State.DN(0 To N - 1)
    ReDim State.X(0 To N - 1)
    ReDim State.D(0 To N - 1)
    ReDim State.G(0 To N - 1)
    ReDim State.GC(0 To N - 1)
    ReDim State.WORK(0 To N - 1)
    ReDim State.YK(0 To N - 1)
    For i_ = 0# To N - 1# Step 1
        State.BndL(i_) = BndL(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.BndU(i_) = BndU(i_)
    Next i_
    
    '
    ' Prepare first run
    '
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = X(i_)
    Next i_
    ReDim State.RState.IA(0# To 3#)
    ReDim State.RState.BA(0# To 1#)
    ReDim State.RState.RA(0# To 2#)
    State.RState.Stage = -1#
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets stopping conditions for the ASA optimization algorithm.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be initialized
'                with MinASACreate()
'    EpsG    -   >=0
'                The  subroutine  finishes  its  work   if   the  condition
'                ||G||<EpsG is satisfied, where ||.|| means Euclidian norm,
'                G - gradient.
'    EpsF    -   >=0
'                The  subroutine  finishes  its work if on k+1-th iteration
'                the  condition  |F(k+1)-F(k)|<=EpsF*max{|F(k)|,|F(k+1)|,1}
'                is satisfied.
'    EpsX    -   >=0
'                The subroutine finishes its work if  on  k+1-th  iteration
'                the condition |X(k+1)-X(k)| <= EpsX is fulfilled.
'    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
'                iterations is unlimited.
'
'Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
'automatic stopping criterion selection (small EpsX).
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinASASetCond(ByRef State As MinASAState, _
         ByVal EpsG As Double, _
         ByVal EpsF As Double, _
         ByVal EpsX As Double, _
         ByVal MaxIts As Long)
    If EpsG = 0# And EpsF = 0# And EpsX = 0# And MaxIts = 0# Then
        EpsX = 0.000001
    End If
    State.EpsG = EpsG
    State.EpsF = EpsF
    State.EpsX = EpsX
    State.MaxIts = MaxIts
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function turns on/off reporting.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinASACreate()
'    NeedXRep-   whether iteration reports are needed or not
'
'Usually  algorithm  returns from  MinASAIteration()  only  when  it  needs
'function/gradient. However, with this function we can let  it  stop  after
'each  iteration  (one  iteration  may  include   more  than  one  function
'evaluation), which is indicated by XUpdated field.
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinASASetXRep(ByRef State As MinASAState, ByVal NeedXRep As Boolean)
    State.XRep = NeedXRep
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets optimization algorithm.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinASACreate()
'    UAType  -   algorithm type:
'                * -1    automatic selection of the best algorithm
'                * 0     DY (Dai and Yuan) algorithm
'                * 1     Hybrid DY-HS algorithm
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinASASetAlgorithm(ByRef State As MinASAState, _
         ByVal AlgoType As Long)
    If AlgoType = -1# Then
        AlgoType = 1#
    End If
    State.CGType = AlgoType
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets maximum step length
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinCGCreate()
'    StpMax  -   maximum step length, >=0. Set StpMax to 0.0,  if you don't
'                want to limit step length.
'
'Use this subroutine when you optimize target function which contains exp()
'or  other  fast  growing  functions,  and optimization algorithm makes too
'large  steps  which  leads  to overflow. This function allows us to reject
'steps  that  are  too  large  (and  therefore  expose  us  to the possible
'overflow) without actually calculating function value at the x+stp*d.
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinASASetStpMax(ByRef State As MinASAState, ByVal StpMax As Double)
    State.StpMax = StpMax
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'One ASA iteration
'
'Called after initialization with MinASACreate.
'See HTML documentation for examples.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be initialized
'                with MinASACreate.
'RESULT:
'* if function returned False, iterative proces has converged.
'  Use MinLBFGSResults() to obtain optimization results.
'* if subroutine returned True, then, depending on structure fields, we
'  have one of the following situations
'
'
'=== FUNC/GRAD REQUEST ===
'State.NeedFG is True => function value/gradient are needed.
'Caller should calculate function value State.F and gradient
'State.G[0..N-1] at State.X[0..N-1] and call MinLBFGSIteration() again.
'
'=== NEW INTERATION IS REPORTED ===
'State.XUpdated is True => one more iteration was made.
'State.X contains current position, State.F contains function value at X.
'You can read info from these fields, but never modify  them  because  they
'contain the only copy of optimization algorithm state.
'
'One and only one of these fields (NeedFG, XUpdated) is true on return. New
'iterations are reported only when reports  are  explicitly  turned  on  by
'MinLBFGSSetXRep() function, so if you never called it, you can expect that
'NeedFG is always True.
'
'
'  -- ALGLIB --
'     Copyright 20.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Function MinASAIteration(ByRef State As MinASAState) As Boolean
    Dim Result As Boolean
    Dim N As Long
    Dim i As Long
    Dim BetaK As Double
    Dim V As Double
    Dim VV As Double
    Dim MCINFO As Long
    Dim B As Boolean
    Dim StepFound As Boolean
    Dim DiffCnt As Long
    Dim i_ As Long
    
    '
    ' Reverse communication preparations
    ' I know it looks ugly, but it works the same way
    ' anywhere from C++ to Python.
    '
    ' This code initializes locals by:
    ' * random values determined during code
    '   generation - on first subroutine call
    ' * values from previous call - on subsequent calls
    '
    If State.RState.Stage >= 0# Then
        N = State.RState.IA(0#)
        i = State.RState.IA(1#)
        MCINFO = State.RState.IA(2#)
        DiffCnt = State.RState.IA(3#)
        B = State.RState.BA(0#)
        StepFound = State.RState.BA(1#)
        BetaK = State.RState.RA(0#)
        V = State.RState.RA(1#)
        VV = State.RState.RA(2#)
    Else
        N = -983#
        i = -989#
        MCINFO = -834#
        DiffCnt = 900#
        B = True
        StepFound = False
        BetaK = 214#
        V = -338#
        VV = -686#
    End If
    If State.RState.Stage = 0# Then
        GoTo lbl_0
    End If
    If State.RState.Stage = 1# Then
        GoTo lbl_1
    End If
    If State.RState.Stage = 2# Then
        GoTo lbl_2
    End If
    If State.RState.Stage = 3# Then
        GoTo lbl_3
    End If
    If State.RState.Stage = 4# Then
        GoTo lbl_4
    End If
    If State.RState.Stage = 5# Then
        GoTo lbl_5
    End If
    If State.RState.Stage = 6# Then
        GoTo lbl_6
    End If
    If State.RState.Stage = 7# Then
        GoTo lbl_7
    End If
    If State.RState.Stage = 8# Then
        GoTo lbl_8
    End If
    If State.RState.Stage = 9# Then
        GoTo lbl_9
    End If
    If State.RState.Stage = 10# Then
        GoTo lbl_10
    End If
    If State.RState.Stage = 11# Then
        GoTo lbl_11
    End If
    If State.RState.Stage = 12# Then
        GoTo lbl_12
    End If
    If State.RState.Stage = 13# Then
        GoTo lbl_13
    End If
    If State.RState.Stage = 14# Then
        GoTo lbl_14
    End If
    
    '
    ' Routine body
    '
    
    '
    ' Prepare
    '
    N = State.N
    State.RepTerminationType = 0#
    State.RepIterationsCount = 0#
    State.RepNFEV = 0#
    State.DebugRestartsCount = 0#
    State.CGType = 1#
    For i_ = 0# To N - 1# Step 1
        State.XK(i_) = State.X(i_)
    Next i_
    For i = 0# To N - 1# Step 1
        If State.XK(i) = State.BndL(i) Or State.XK(i) = State.BndU(i) Then
            State.AK(i) = 0#
        Else
            State.AK(i) = 1#
        End If
    Next i
    State.Mu = 0.1
    State.CurAlgo = 0#
    
    '
    ' Calculate F/G, initialize algorithm
    '
    Call ClearRequestFields(State)
    State.NeedFG = True
    State.RState.Stage = 0#
    GoTo lbl_rcomm
lbl_0:
    If Not State.XRep Then
        GoTo lbl_15
    End If
    
    '
    ' progress report
    '
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 1#
    GoTo lbl_rcomm
lbl_1:
lbl_15:
    If ASABoundedAntiGradNorm(State) <= State.EpsG Then
        State.RepTerminationType = 4#
        Result = False
        MinASAIteration = Result
        Exit Function
    End If
    State.RepNFEV = State.RepNFEV + 1#
    
    '
    ' Main cycle
    '
    ' At the beginning of new iteration:
    ' * CurAlgo stores current algorithm selector
    ' * State.XK, State.F and State.G store current X/F/G
    ' * State.AK stores current set of active constraints
    '
lbl_17:
    If False Then
        GoTo lbl_18
    End If
    
    '
    ' GPA algorithm
    '
    If State.CurAlgo <> 0# Then
        GoTo lbl_19
    End If
    State.K = 0#
    State.ACount = 0#
lbl_21:
    If False Then
        GoTo lbl_22
    End If
    
    '
    ' Determine Dk = proj(xk - gk)-xk
    '
    For i = 0# To N - 1# Step 1
        State.D(i) = ASABoundVal(State.XK(i) - State.G(i), State.BndL(i), State.BndU(i)) - State.XK(i)
    Next i
    
    '
    ' Armijo line search.
    ' * exact search with alpha=1 is tried first,
    '   'exact' means that we evaluate f() EXACTLY at
    '   bound(x-g,bndl,bndu), without intermediate floating
    '   point operations.
    ' * alpha<1 are tried if explicit search wasn't successful
    ' Result is placed into XN.
    '
    ' Two types of search are needed because we can't
    ' just use second type with alpha=1 because in finite
    ' precision arithmetics (x1-x0)+x0 may differ from x1.
    ' So while x1 is correctly bounded (it lie EXACTLY on
    ' boundary, if it is active), (x1-x0)+x0 may be
    ' not bounded.
    '
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.D(i_) * State.G(i_)
    Next i_
    State.DGInit = V
    State.FInit = State.F
    If Not (ASAD1Norm(State) <= State.StpMax Or State.StpMax = 0#) Then
        GoTo lbl_23
    End If
    
    '
    ' Try alpha=1 step first
    '
    For i = 0# To N - 1# Step 1
        State.X(i) = ASABoundVal(State.XK(i) - State.G(i), State.BndL(i), State.BndU(i))
    Next i
    Call ClearRequestFields(State)
    State.NeedFG = True
    State.RState.Stage = 2#
    GoTo lbl_rcomm
lbl_2:
    State.RepNFEV = State.RepNFEV + 1#
    StepFound = State.F <= State.FInit + GPAFTol * State.DGInit
    GoTo lbl_24
lbl_23:
    StepFound = False
lbl_24:
    If Not StepFound Then
        GoTo lbl_25
    End If
    
    '
    ' we are at the boundary(ies)
    '
    For i_ = 0# To N - 1# Step 1
        State.XN(i_) = State.X(i_)
    Next i_
    State.Stp = 1#
    GoTo lbl_26
lbl_25:
    
    '
    ' alpha=1 is too large, try smaller values
    '
    State.Stp = 1#
    Call LinMinNormalizeD(State.D, State.Stp, N)
    State.DGInit = State.DGInit / State.Stp
    State.Stp = GPADecay * State.Stp
    If State.StpMax > 0# Then
        State.Stp = MinReal(State.Stp, State.StpMax)
    End If
lbl_27:
    If False Then
        GoTo lbl_28
    End If
    V = State.Stp
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = State.XK(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = State.X(i_) + V * State.D(i_)
    Next i_
    Call ClearRequestFields(State)
    State.NeedFG = True
    State.RState.Stage = 3#
    GoTo lbl_rcomm
lbl_3:
    State.RepNFEV = State.RepNFEV + 1#
    If State.Stp <= STPMIN Then
        GoTo lbl_28
    End If
    If State.F <= State.FInit + State.Stp * GPAFTol * State.DGInit Then
        GoTo lbl_28
    End If
    State.Stp = State.Stp * GPADecay
    GoTo lbl_27
lbl_28:
    For i_ = 0# To N - 1# Step 1
        State.XN(i_) = State.X(i_)
    Next i_
lbl_26:
    State.RepIterationsCount = State.RepIterationsCount + 1#
    If Not State.XRep Then
        GoTo lbl_29
    End If
    
    '
    ' progress report
    '
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 4#
    GoTo lbl_rcomm
lbl_4:
lbl_29:
    
    '
    ' Calculate new set of active constraints.
    ' Reset counter if active set was changed.
    ' Prepare for the new iteration
    '
    For i = 0# To N - 1# Step 1
        If State.XN(i) = State.BndL(i) Or State.XN(i) = State.BndU(i) Then
            State.AN(i) = 0#
        Else
            State.AN(i) = 1#
        End If
    Next i
    For i = 0# To N - 1# Step 1
        If State.AK(i) <> State.AN(i) Then
            State.ACount = -1#
            Exit For
        End If
    Next i
    State.ACount = State.ACount + 1#
    For i_ = 0# To N - 1# Step 1
        State.XK(i_) = State.XN(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.AK(i_) = State.AN(i_)
    Next i_
    
    '
    ' Stopping conditions
    '
    If Not (State.RepIterationsCount >= State.MaxIts And State.MaxIts > 0#) Then
        GoTo lbl_31
    End If
    
    '
    ' Too many iterations
    '
    State.RepTerminationType = 5#
    If Not State.XRep Then
        GoTo lbl_33
    End If
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 5#
    GoTo lbl_rcomm
lbl_5:
lbl_33:
    Result = False
    MinASAIteration = Result
    Exit Function
lbl_31:
    If ASABoundedAntiGradNorm(State) > State.EpsG Then
        GoTo lbl_35
    End If
    
    '
    ' Gradient is small enough
    '
    State.RepTerminationType = 4#
    If Not State.XRep Then
        GoTo lbl_37
    End If
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 6#
    GoTo lbl_rcomm
lbl_6:
lbl_37:
    Result = False
    MinASAIteration = Result
    Exit Function
lbl_35:
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.D(i_) * State.D(i_)
    Next i_
    If Sqr(V) * State.Stp > State.EpsX Then
        GoTo lbl_39
    End If
    
    '
    ' Step size is too small, no further improvement is
    ' possible
    '
    State.RepTerminationType = 2#
    If Not State.XRep Then
        GoTo lbl_41
    End If
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 7#
    GoTo lbl_rcomm
lbl_7:
lbl_41:
    Result = False
    MinASAIteration = Result
    Exit Function
lbl_39:
    If State.FInit - State.F > State.EpsF * MaxReal(Abs(State.FInit), MaxReal(Abs(State.F), 1#)) Then
        GoTo lbl_43
    End If
    
    '
    ' F(k+1)-F(k) is small enough
    '
    State.RepTerminationType = 1#
    If Not State.XRep Then
        GoTo lbl_45
    End If
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 8#
    GoTo lbl_rcomm
lbl_8:
lbl_45:
    Result = False
    MinASAIteration = Result
    Exit Function
lbl_43:
    
    '
    ' Decide - should we switch algorithm or not
    '
    If ASAUIsEmpty(State) Then
        If ASAGINorm(State) >= State.Mu * ASAD1Norm(State) Then
            State.CurAlgo = 1#
            GoTo lbl_22
        Else
            State.Mu = State.Mu * ASARho
        End If
    Else
        If State.ACount = N1 Then
            If ASAGINorm(State) >= State.Mu * ASAD1Norm(State) Then
                State.CurAlgo = 1#
                GoTo lbl_22
            End If
        End If
    End If
    
    '
    ' Next iteration
    '
    State.K = State.K + 1#
    GoTo lbl_21
lbl_22:
lbl_19:
    
    '
    ' CG algorithm
    '
    If State.CurAlgo <> 1# Then
        GoTo lbl_47
    End If
    
    '
    ' first, check that there are non-active constraints.
    ' move to GPA algorithm, if all constraints are active
    '
    B = True
    For i = 0# To N - 1# Step 1
        If State.AK(i) <> 0# Then
            B = False
            Exit For
        End If
    Next i
    If B Then
        State.CurAlgo = 0#
        GoTo lbl_17
    End If
    
    '
    ' CG iterations
    '
    State.Fold = State.F
    For i_ = 0# To N - 1# Step 1
        State.XK(i_) = State.X(i_)
    Next i_
    For i = 0# To N - 1# Step 1
        State.DK(i) = -(State.G(i) * State.AK(i))
        State.GC(i) = State.G(i) * State.AK(i)
    Next i
lbl_49:
    If False Then
        GoTo lbl_50
    End If
    
    '
    ' Store G[k] for later calculation of Y[k]
    '
    For i = 0# To N - 1# Step 1
        State.YK(i) = -State.GC(i)
    Next i
    
    '
    ' Make a CG step in direction given by DK[]:
    ' * calculate step. Step projection into feasible set
    '   is used. It has several benefits: a) step may be
    '   found with usual line search, b) multiple constraints
    '   may be activated with one step, c) activated constraints
    '   are detected in a natural way - just compare x[i] with
    '   bounds
    ' * update active set, set B to True, if there
    '   were changes in the set.
    '
    For i_ = 0# To N - 1# Step 1
        State.D(i_) = State.DK(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.XN(i_) = State.XK(i_)
    Next i_
    State.MCStage = 0#
    State.Stp = 1#
    Call LinMinNormalizeD(State.D, State.Stp, N)
    Call MCSRCH(N, State.XN, State.F, State.GC, State.D, State.Stp, State.StpMax, MCINFO, State.NFEV, State.WORK, State.LState, State.MCStage)
lbl_51:
    If State.MCStage = 0# Then
        GoTo lbl_52
    End If
    
    '
    ' preprocess data: bound State.XN so it belongs to the
    ' feasible set and store it in the State.X
    '
    For i = 0# To N - 1# Step 1
        State.X(i) = ASABoundVal(State.XN(i), State.BndL(i), State.BndU(i))
    Next i
    
    '
    ' RComm
    '
    Call ClearRequestFields(State)
    State.NeedFG = True
    State.RState.Stage = 9#
    GoTo lbl_rcomm
lbl_9:
    
    '
    ' postprocess data: zero components of G corresponding to
    ' the active constraints
    '
    For i = 0# To N - 1# Step 1
        If State.X(i) = State.BndL(i) Or State.X(i) = State.BndU(i) Then
            State.GC(i) = 0#
        Else
            State.GC(i) = State.G(i)
        End If
    Next i
    Call MCSRCH(N, State.XN, State.F, State.GC, State.D, State.Stp, State.StpMax, MCINFO, State.NFEV, State.WORK, State.LState, State.MCStage)
    GoTo lbl_51
lbl_52:
    DiffCnt = 0#
    For i = 0# To N - 1# Step 1
        
        '
        ' XN contains unprojected result, project it,
        ' save copy to X (will be used for progress reporting)
        '
        State.XN(i) = ASABoundVal(State.XN(i), State.BndL(i), State.BndU(i))
        
        '
        ' update active set
        '
        If State.XN(i) = State.BndL(i) Or State.XN(i) = State.BndU(i) Then
            State.AN(i) = 0#
        Else
            State.AN(i) = 1#
        End If
        If State.AN(i) <> State.AK(i) Then
            DiffCnt = DiffCnt + 1#
        End If
        State.AK(i) = State.AN(i)
    Next i
    For i_ = 0# To N - 1# Step 1
        State.XK(i_) = State.XN(i_)
    Next i_
    State.RepNFEV = State.RepNFEV + State.NFEV
    State.RepIterationsCount = State.RepIterationsCount + 1#
    If Not State.XRep Then
        GoTo lbl_53
    End If
    
    '
    ' progress report
    '
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 10#
    GoTo lbl_rcomm
lbl_10:
lbl_53:
    
    '
    ' Check stopping conditions.
    '
    If ASABoundedAntiGradNorm(State) > State.EpsG Then
        GoTo lbl_55
    End If
    
    '
    ' Gradient is small enough
    '
    State.RepTerminationType = 4#
    If Not State.XRep Then
        GoTo lbl_57
    End If
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 11#
    GoTo lbl_rcomm
lbl_11:
lbl_57:
    Result = False
    MinASAIteration = Result
    Exit Function
lbl_55:
    If Not (State.RepIterationsCount >= State.MaxIts And State.MaxIts > 0#) Then
        GoTo lbl_59
    End If
    
    '
    ' Too many iterations
    '
    State.RepTerminationType = 5#
    If Not State.XRep Then
        GoTo lbl_61
    End If
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 12#
    GoTo lbl_rcomm
lbl_12:
lbl_61:
    Result = False
    MinASAIteration = Result
    Exit Function
lbl_59:
    If Not (ASAGINorm(State) >= State.Mu * ASAD1Norm(State) And DiffCnt = 0#) Then
        GoTo lbl_63
    End If
    
    '
    ' These conditions are explicitly or implicitly
    ' related to the current step size and influenced
    ' by changes in the active constraints.
    '
    ' For these reasons they are checked only when we don't
    ' want to 'unstick' at the end of the iteration and there
    ' were no changes in the active set.
    '
    ' NOTE: consition |G|>=Mu*|D1| must be exactly opposite
    ' to the condition used to switch back to GPA. At least
    ' one inequality must be strict, otherwise infinite cycle
    ' may occur when |G|=Mu*|D1| (we DON'T test stopping
    ' conditions and we DON'T switch to GPA, so we cycle
    ' indefinitely).
    '
    If State.Fold - State.F > State.EpsF * MaxReal(Abs(State.Fold), MaxReal(Abs(State.F), 1#)) Then
        GoTo lbl_65
    End If
    
    '
    ' F(k+1)-F(k) is small enough
    '
    State.RepTerminationType = 1#
    If Not State.XRep Then
        GoTo lbl_67
    End If
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 13#
    GoTo lbl_rcomm
lbl_13:
lbl_67:
    Result = False
    MinASAIteration = Result
    Exit Function
lbl_65:
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.D(i_) * State.D(i_)
    Next i_
    If Sqr(V) * State.Stp > State.EpsX Then
        GoTo lbl_69
    End If
    
    '
    ' X(k+1)-X(k) is small enough
    '
    State.RepTerminationType = 2#
    If Not State.XRep Then
        GoTo lbl_71
    End If
    Call ClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 14#
    GoTo lbl_rcomm
lbl_14:
lbl_71:
    Result = False
    MinASAIteration = Result
    Exit Function
lbl_69:
lbl_63:
    
    '
    ' Check conditions for switching
    '
    If ASAGINorm(State) < State.Mu * ASAD1Norm(State) Then
        State.CurAlgo = 0#
        GoTo lbl_50
    End If
    If DiffCnt > 0# Then
        If ASAUIsEmpty(State) Or DiffCnt >= N2 Then
            State.CurAlgo = 1#
        Else
            State.CurAlgo = 0#
        End If
        GoTo lbl_50
    End If
    
    '
    ' Calculate D(k+1)
    '
    ' Line search may result in:
    ' * maximum feasible step being taken (already processed)
    ' * point satisfying Wolfe conditions
    ' * some kind of error (CG is restarted by assigning 0.0 to Beta)
    '
    If MCINFO = 1# Then
        
        '
        ' Standard Wolfe conditions are satisfied:
        ' * calculate Y[K] and BetaK
        '
        For i_ = 0# To N - 1# Step 1
            State.YK(i_) = State.YK(i_) + State.GC(i_)
        Next i_
        VV = 0#
        For i_ = 0# To N - 1# Step 1
            VV = VV + State.YK(i_) * State.DK(i_)
        Next i_
        V = 0#
        For i_ = 0# To N - 1# Step 1
            V = V + State.GC(i_) * State.GC(i_)
        Next i_
        State.BetaDY = V / VV
        V = 0#
        For i_ = 0# To N - 1# Step 1
            V = V + State.GC(i_) * State.YK(i_)
        Next i_
        State.BetaHS = V / VV
        If State.CGType = 0# Then
            BetaK = State.BetaDY
        End If
        If State.CGType = 1# Then
            BetaK = MaxReal(0#, MinReal(State.BetaDY, State.BetaHS))
        End If
    Else
        
        '
        ' Something is wrong (may be function is too wild or too flat).
        '
        ' We'll set BetaK=0, which will restart CG algorithm.
        ' We can stop later (during normal checks) if stopping conditions are met.
        '
        BetaK = 0#
        State.DebugRestartsCount = State.DebugRestartsCount + 1#
    End If
    For i_ = 0# To N - 1# Step 1
        State.DN(i_) = -State.GC(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.DN(i_) = State.DN(i_) + BetaK * State.DK(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.DK(i_) = State.DN(i_)
    Next i_
    
    '
    ' update other information
    '
    State.Fold = State.F
    State.K = State.K + 1#
    GoTo lbl_49
lbl_50:
lbl_47:
    GoTo lbl_17
lbl_18:
    Result = False
    MinASAIteration = Result
    Exit Function
    
    '
    ' Saving state
    '
lbl_rcomm:
    Result = True
    State.RState.IA(0#) = N
    State.RState.IA(1#) = i
    State.RState.IA(2#) = MCINFO
    State.RState.IA(3#) = DiffCnt
    State.RState.BA(0#) = B
    State.RState.BA(1#) = StepFound
    State.RState.RA(0#) = BetaK
    State.RState.RA(1#) = V
    State.RState.RA(2#) = VV
    MinASAIteration = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Conjugate gradient results
'
'Called after MinASA returned False.
'
'INPUT PARAMETERS:
'    State   -   algorithm state (used by MinASAIteration).
'
'OUTPUT PARAMETERS:
'    X       -   array[0..N-1], solution
'    Rep     -   optimization report:
'                * Rep.TerminationType completetion code:
'                    * -2    rounding errors prevent further improvement.
'                            X contains best point found.
'                    * -1    incorrect parameters were specified
'                    *  1    relative function improvement is no more than
'                            EpsF.
'                    *  2    relative step is no more than EpsX.
'                    *  4    gradient norm is no more than EpsG
'                    *  5    MaxIts steps was taken
'                    *  7    stopping conditions are too stringent,
'                            further improvement is impossible
'                * Rep.IterationsCount contains iterations count
'                * NFEV countains number of function calculations
'                * ActiveConstraints contains number of active constraints
'
'  -- ALGLIB --
'     Copyright 20.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinASAResults(ByRef State As MinASAState, _
         ByRef X() As Double, _
         ByRef Rep As MinASAReport)
    Dim i As Long
    Dim i_ As Long
    ReDim X(0# To State.N - 1#)
    For i_ = 0# To State.N - 1# Step 1
        X(i_) = State.X(i_)
    Next i_
    Rep.IterationsCount = State.RepIterationsCount
    Rep.NFEV = State.RepNFEV
    Rep.TerminationType = State.RepTerminationType
    Rep.ActiveConstraints = 0#
    For i = 0# To State.N - 1# Step 1
        If State.AK(i) = 0# Then
            Rep.ActiveConstraints = Rep.ActiveConstraints + 1#
        End If
    Next i
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
''bound' value: map X to [B1,B2]
'
'  -- ALGLIB --
'     Copyright 20.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Function ASABoundVal(ByVal X As Double, _
         ByVal b1 As Double, _
         ByVal b2 As Double) As Double
    Dim Result As Double
    If X <= b1 Then
        Result = b1
        ASABoundVal = Result
        Exit Function
    End If
    If X >= b2 Then
        Result = b2
        ASABoundVal = Result
        Exit Function
    End If
    Result = X
    ASABoundVal = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Returns norm of bounded anti-gradient.
'
'Bounded antigradient is a vector obtained from  anti-gradient  by  zeroing
'components which point outwards:
'    result = norm(v)
'    v[i]=0     if ((-g[i]<0)and(x[i]=bndl[i])) or
'                  ((-g[i]>0)and(x[i]=bndu[i]))
'    v[i]=-g[i] otherwise
'
'This function may be used to check a stopping criterion.
'
'  -- ALGLIB --
'     Copyright 20.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Function ASABoundedAntiGradNorm(ByRef State As MinASAState) As Double
    Dim Result As Double
    Dim i As Long
    Dim V As Double
    Result = 0#
    For i = 0# To State.N - 1# Step 1
        V = -State.G(i)
        If State.X(i) = State.BndL(i) And -State.G(i) < 0# Then
            V = 0#
        End If
        If State.X(i) = State.BndU(i) And -State.G(i) > 0# Then
            V = 0#
        End If
        Result = Result + Square(V)
    Next i
    Result = Sqr(Result)
    ASABoundedAntiGradNorm = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Returns norm of GI(x).
'
'GI(x) is  a  gradient  vector  whose  components  associated  with  active
'constraints are zeroed. It  differs  from  bounded  anti-gradient  because
'components  of   GI(x)   are   zeroed  independently  of  sign(g[i]),  and
'anti-gradient's components are zeroed with respect to both constraint  and
'sign.
'
'  -- ALGLIB --
'     Copyright 20.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Function ASAGINorm(ByRef State As MinASAState) As Double
    Dim Result As Double
    Dim i As Long
    Dim V As Double
    Result = 0#
    For i = 0# To State.N - 1# Step 1
        If State.X(i) <> State.BndL(i) And State.X(i) <> State.BndU(i) Then
            Result = Result + Square(State.G(i))
        End If
    Next i
    Result = Sqr(Result)
    ASAGINorm = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Returns norm(D1(State.X))
'
'For a meaning of D1 see 'NEW ACTIVE SET ALGORITHM FOR BOX CONSTRAINED
'OPTIMIZATION' by WILLIAM W. HAGER AND HONGCHAO ZHANG.
'
'  -- ALGLIB --
'     Copyright 20.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Function ASAD1Norm(ByRef State As MinASAState) As Double
    Dim Result As Double
    Dim i As Long
    Result = 0#
    For i = 0# To State.N - 1# Step 1
        Result = Result + Square(ASABoundVal(State.X(i) - State.G(i), State.BndL(i), State.BndU(i)) - State.X(i))
    Next i
    Result = Sqr(Result)
    ASAD1Norm = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Returns True, if U set is empty.
'
'* State.X is used as point,
'* State.G - as gradient,
'* D is calculated within function (because State.D may have different
'  meaning depending on current optimization algorithm)
'
'For a meaning of U see 'NEW ACTIVE SET ALGORITHM FOR BOX CONSTRAINED
'OPTIMIZATION' by WILLIAM W. HAGER AND HONGCHAO ZHANG.
'
'  -- ALGLIB --
'     Copyright 20.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Function ASAUIsEmpty(ByRef State As MinASAState) As Boolean
    Dim Result As Boolean
    Dim i As Long
    Dim D As Double
    Dim D2 As Double
    Dim D32 As Double
    D = ASAD1Norm(State)
    D2 = Sqr(D)
    D32 = D * D2
    Result = True
    For i = 0# To State.N - 1# Step 1
        If Abs(State.G(i)) >= D2 And MinReal(State.X(i) - State.BndL(i), State.BndU(i) - State.X(i)) >= D32 Then
            Result = False
            ASAUIsEmpty = Result
            Exit Function
        End If
    Next i
    ASAUIsEmpty = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Returns True, if optimizer "want  to  unstick"  from  one  of  the  active
'constraints, i.e. there is such active constraint with index I that either
'lower bound is active and g[i]<0, or upper bound is active and g[i]>0.
'
'State.X is used as current point, State.X - as gradient.
'  -- ALGLIB --
'     Copyright 20.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Function ASAWantToUnstick(ByRef State As MinASAState) As Boolean
    Dim Result As Boolean
    Dim i As Long
    Result = False
    For i = 0# To State.N - 1# Step 1
        If State.X(i) = State.BndL(i) And State.G(i) < 0# Then
            Result = True
        End If
        If State.X(i) = State.BndU(i) And State.G(i) > 0# Then
            Result = True
        End If
        If Result Then
            ASAWantToUnstick = Result
            Exit Function
        End If
    Next i
    ASAWantToUnstick = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Clears request fileds (to be sure that we don't forgot to clear something)
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Sub ClearRequestFields(ByRef State As MinASAState)
    State.NeedFG = False
    State.XUpdated = False
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Copyright (c) 2010, Sergey Bochkanov (ALGLIB project).
'
'>>> SOURCE LICENSE >>>
'This program is free software; you can redistribute it and/or modify
'it under the terms of the GNU General Public License as published by
'the Free Software Foundation (www.fsf.org); either version 2 of the
'License, or (at your option) any later version.
'
'This program is distributed in the hope that it will be useful,
'but WITHOUT ANY WARRANTY; without even the implied warranty of
'MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
'GNU General Public License for more details.
'
'A copy of the GNU General Public License is available at
'http://www.fsf.org/licensing/licenses
'
'>>> END OF LICENSE >>>
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Routines
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'        NONLINEAR CONJUGATE GRADIENT METHOD
'
'The subroutine minimizes function F(x) of N arguments by using one of  the
'nonlinear conjugate gradient methods.
'
'These CG methods are globally convergent (even on non-convex functions) as
'long as grad(f) is Lipschitz continuous in  a  some  neighborhood  of  the
'L = { x : f(x)<=f(x0) }.
'
'INPUT PARAMETERS:
'    N       -   problem dimension. N>0
'    X       -   initial solution approximation, array[0..N-1].
'    EpsG    -   positive number which  defines  a  precision  of  search.  The
'                subroutine finishes its work if the condition ||G|| < EpsG  is
'                satisfied, where ||.|| means Euclidian norm, G - gradient, X -
'                current approximation.
'    EpsF    -   positive number which  defines  a  precision  of  search.  The
'                subroutine finishes its work if on iteration  number  k+1  the
'                condition |F(k+1)-F(k)| <= EpsF*max{|F(k)|, |F(k+1)|, 1}    is
'                satisfied.
'    EpsX    -   positive number which  defines  a  precision  of  search.  The
'                subroutine finishes its work if on iteration number k+1    the
'                condition |X(k+1)-X(k)| <= EpsX is fulfilled.
'    MaxIts  -   maximum number of iterations. If MaxIts=0, the number of
'                iterations is unlimited.
'
'OUTPUT PARAMETERS:
'    State - structure used for reverse communication.
'
'See also MinCGIteration, MinCGResults
'
'NOTE:
'
'Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
'automatic stopping criterion selection (small EpsX).
'
'  -- ALGLIB --
'     Copyright 25.03.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGCreate(ByVal N As Long, _
         ByRef X() As Double, _
         ByRef State As MinCGState)
    Dim i_ As Long
    
    '
    ' Initialize
    '
    State.N = N
    Call MinCGSetCond(State, 0#, 0#, 0#, 0#)
    Call MinCGSetXRep(State, False)
    Call MinCGSetStpMax(State, 0#)
    Call MinCGSetCGType(State, -1#)
    ReDim State.XK(0 To N - 1)
    ReDim State.DK(0 To N - 1)
    ReDim State.XN(0 To N - 1)
    ReDim State.DN(0 To N - 1)
    ReDim State.X(0 To N - 1)
    ReDim State.D(0 To N - 1)
    ReDim State.G(0 To N - 1)
    ReDim State.WORK(0 To N - 1)
    ReDim State.YK(0 To N - 1)
    
    '
    ' Prepare first run
    '
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = X(i_)
    Next i_
    ReDim State.RState.IA(0# To 2#)
    ReDim State.RState.RA(0# To 2#)
    State.RState.Stage = -1#
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets stopping conditions for CG optimization algorithm.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be initialized
'                with MinCGCreate()
'    EpsG    -   >=0
'                The  subroutine  finishes  its  work   if   the  condition
'                ||G||<EpsG is satisfied, where ||.|| means Euclidian norm,
'                G - gradient.
'    EpsF    -   >=0
'                The  subroutine  finishes  its work if on k+1-th iteration
'                the  condition  |F(k+1)-F(k)|<=EpsF*max{|F(k)|,|F(k+1)|,1}
'                is satisfied.
'    EpsX    -   >=0
'                The subroutine finishes its work if  on  k+1-th  iteration
'                the condition |X(k+1)-X(k)| <= EpsX is fulfilled.
'    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
'                iterations is unlimited.
'
'Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
'automatic stopping criterion selection (small EpsX).
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGSetCond(ByRef State As MinCGState, _
         ByVal EpsG As Double, _
         ByVal EpsF As Double, _
         ByVal EpsX As Double, _
         ByVal MaxIts As Long)
    If EpsG = 0# And EpsF = 0# And EpsX = 0# And MaxIts = 0# Then
        EpsX = 0.000001
    End If
    State.EpsG = EpsG
    State.EpsF = EpsF
    State.EpsX = EpsX
    State.MaxIts = MaxIts
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function turns on/off reporting.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinCGCreate()
'    NeedXRep-   whether iteration reports are needed or not
'
'Usually  algorithm  returns  from  MinCGIteration()  only  when  it  needs
'function/gradient. However, with this function we can let  it  stop  after
'each  iteration  (one  iteration  may  include   more  than  one  function
'evaluation), which is indicated by XUpdated field.
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGSetXRep(ByRef State As MinCGState, ByVal NeedXRep As Boolean)
    State.XRep = NeedXRep
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets CG algorithm.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinCGCreate()
'    CGType  -   algorithm type:
'                * -1    automatic selection of the best algorithm
'                * 0     DY (Dai and Yuan) algorithm
'                * 1     Hybrid DY-HS algorithm
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGSetCGType(ByRef State As MinCGState, ByVal CGType As Long)
    If CGType = -1# Then
        CGType = 1#
    End If
    State.CGType = CGType
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets maximum step length
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinCGCreate()
'    StpMax  -   maximum step length, >=0. Set StpMax to 0.0,  if you don't
'                want to limit step length.
'
'Use this subroutine when you optimize target function which contains exp()
'or  other  fast  growing  functions,  and optimization algorithm makes too
'large  steps  which  leads  to overflow. This function allows us to reject
'steps  that  are  too  large  (and  therefore  expose  us  to the possible
'overflow) without actually calculating function value at the x+stp*d.
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGSetStpMax(ByRef State As MinCGState, ByVal StpMax As Double)
    State.StpMax = StpMax
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'One conjugate gradient iteration
'
'Called after initialization with MinCG.
'See HTML documentation for examples.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be initialized
'                with MinCG.
'
'RESULT:
'* if function returned False, iterative proces has converged.
'  Use MinLBFGSResults() to obtain optimization results.
'* if subroutine returned True, then, depending on structure fields, we
'  have one of the following situations
'
'
'=== FUNC/GRAD REQUEST ===
'State.NeedFG is True => function value/gradient are needed.
'Caller should calculate function value State.F and gradient
'State.G[0..N-1] at State.X[0..N-1] and call MinLBFGSIteration() again.
'
'=== NEW INTERATION IS REPORTED ===
'State.XUpdated is True => one more iteration was made.
'State.X contains current position, State.F contains function value at X.
'You can read info from these fields, but never modify  them  because  they
'contain the only copy of optimization algorithm state.
'
'One and only one of these fields (NeedFG, XUpdated) is true on return. New
'iterations are reported only when reports  are  explicitly  turned  on  by
'MinLBFGSSetXRep() function, so if you never called it, you can expect that
'NeedFG is always True.
'
'
'  -- ALGLIB --
'     Copyright 20.04.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Function MinCGIteration(ByRef State As MinCGState) As Boolean
    Dim Result As Boolean
    Dim N As Long
    Dim i As Long
    Dim BetaK As Double
    Dim V As Double
    Dim VV As Double
    Dim MCINFO As Long
    Dim i_ As Long
    
    '
    ' Reverse communication preparations
    ' I know it looks ugly, but it works the same way
    ' anywhere from C++ to Python.
    '
    ' This code initializes locals by:
    ' * random values determined during code
    '   generation - on first subroutine call
    ' * values from previous call - on subsequent calls
    '
    If State.RState.Stage >= 0# Then
        N = State.RState.IA(0#)
        i = State.RState.IA(1#)
        MCINFO = State.RState.IA(2#)
        BetaK = State.RState.RA(0#)
        V = State.RState.RA(1#)
        VV = State.RState.RA(2#)
    Else
        N = -983#
        i = -989#
        MCINFO = -834#
        BetaK = 900#
        V = -287#
        VV = 364#
    End If
    If State.RState.Stage = 0# Then
        GoTo lbl_0
    End If
    If State.RState.Stage = 1# Then
        GoTo lbl_1
    End If
    If State.RState.Stage = 2# Then
        GoTo lbl_2
    End If
    If State.RState.Stage = 3# Then
        GoTo lbl_3
    End If
    
    '
    ' Routine body
    '
    
    '
    ' Prepare
    '
    N = State.N
    State.RepTerminationType = 0#
    State.RepIterationsCount = 0#
    State.RepNFEV = 0#
    State.DebugRestartsCount = 0#
    
    '
    ' Calculate F/G, initialize algorithm
    '
    Call ClearRequestFieldsCG(State)
    State.NeedFG = True
    State.RState.Stage = 0#
    GoTo lbl_rcomm
lbl_0:
    If Not State.XRep Then
        GoTo lbl_4
    End If
    Call ClearRequestFieldsCG(State)
    State.XUpdated = True
    State.RState.Stage = 1#
    GoTo lbl_rcomm
lbl_1:
lbl_4:
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.G(i_) * State.G(i_)
    Next i_
    V = Sqr(V)
    If V = 0# Then
        State.RepTerminationType = 4#
        Result = False
        MinCGIteration = Result
        Exit Function
    End If
    State.RepNFEV = 1#
    State.K = 0#
    State.Fold = State.F
    For i_ = 0# To N - 1# Step 1
        State.XK(i_) = State.X(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.DK(i_) = -State.G(i_)
    Next i_
    
    '
    ' Main cycle
    '
lbl_6:
    If False Then
        GoTo lbl_7
    End If
    
    '
    ' Store G[k] for later calculation of Y[k]
    '
    For i_ = 0# To N - 1# Step 1
        State.YK(i_) = -State.G(i_)
    Next i_
    
    '
    ' Calculate X(k+1): minimize F(x+alpha*d)
    '
    For i_ = 0# To N - 1# Step 1
        State.D(i_) = State.DK(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = State.XK(i_)
    Next i_
    State.MCStage = 0#
    State.Stp = 1#
    Call LinMinNormalizeD(State.D, State.Stp, N)
    Call MCSRCH(N, State.X, State.F, State.G, State.D, State.Stp, State.StpMax, MCINFO, State.NFEV, State.WORK, State.LState, State.MCStage)
lbl_8:
    If State.MCStage = 0# Then
        GoTo lbl_9
    End If
    Call ClearRequestFieldsCG(State)
    State.NeedFG = True
    State.RState.Stage = 2#
    GoTo lbl_rcomm
lbl_2:
    Call MCSRCH(N, State.X, State.F, State.G, State.D, State.Stp, State.StpMax, MCINFO, State.NFEV, State.WORK, State.LState, State.MCStage)
    GoTo lbl_8
lbl_9:
    If Not State.XRep Then
        GoTo lbl_10
    End If
    Call ClearRequestFieldsCG(State)
    State.XUpdated = True
    State.RState.Stage = 3#
    GoTo lbl_rcomm
lbl_3:
lbl_10:
    For i_ = 0# To N - 1# Step 1
        State.XN(i_) = State.X(i_)
    Next i_
    If MCINFO = 1# Then
        
        '
        ' Standard Wolfe conditions hold
        ' Calculate Y[K] and BetaK
        '
        For i_ = 0# To N - 1# Step 1
            State.YK(i_) = State.YK(i_) + State.G(i_)
        Next i_
        VV = 0#
        For i_ = 0# To N - 1# Step 1
            VV = VV + State.YK(i_) * State.DK(i_)
        Next i_
        V = 0#
        For i_ = 0# To N - 1# Step 1
            V = V + State.G(i_) * State.G(i_)
        Next i_
        State.BetaDY = V / VV
        V = 0#
        For i_ = 0# To N - 1# Step 1
            V = V + State.G(i_) * State.YK(i_)
        Next i_
        State.BetaHS = V / VV
        If State.CGType = 0# Then
            BetaK = State.BetaDY
        End If
        If State.CGType = 1# Then
            BetaK = MaxReal(0#, MinReal(State.BetaDY, State.BetaHS))
        End If
    Else
        
        '
        ' Something is wrong (may be function is too wild or too flat).
        '
        ' We'll set BetaK=0, which will restart CG algorithm.
        ' We can stop later (during normal checks) if stopping conditions are met.
        '
        BetaK = 0#
        State.DebugRestartsCount = State.DebugRestartsCount + 1#
    End If
    
    '
    ' Calculate D(k+1)
    '
    For i_ = 0# To N - 1# Step 1
        State.DN(i_) = -State.G(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.DN(i_) = State.DN(i_) + BetaK * State.DK(i_)
    Next i_
    
    '
    ' Update information and Hessian.
    ' Check stopping conditions.
    '
    State.RepNFEV = State.RepNFEV + State.NFEV
    State.RepIterationsCount = State.RepIterationsCount + 1#
    If State.RepIterationsCount >= State.MaxIts And State.MaxIts > 0# Then
        
        '
        ' Too many iterations
        '
        State.RepTerminationType = 5#
        Result = False
        MinCGIteration = Result
        Exit Function
    End If
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.G(i_) * State.G(i_)
    Next i_
    If Sqr(V) <= State.EpsG Then
        
        '
        ' Gradient is small enough
        '
        State.RepTerminationType = 4#
        Result = False
        MinCGIteration = Result
        Exit Function
    End If
    If State.Fold - State.F <= State.EpsF * MaxReal(Abs(State.Fold), MaxReal(Abs(State.F), 1#)) Then
        
        '
        ' F(k+1)-F(k) is small enough
        '
        State.RepTerminationType = 1#
        Result = False
        MinCGIteration = Result
        Exit Function
    End If
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.D(i_) * State.D(i_)
    Next i_
    If Sqr(V) * State.Stp <= State.EpsX Then
        
        '
        ' X(k+1)-X(k) is small enough
        '
        State.RepTerminationType = 2#
        Result = False
        MinCGIteration = Result
        Exit Function
    End If
    
    '
    ' Shift Xk/Dk, update other information
    '
    For i_ = 0# To N - 1# Step 1
        State.XK(i_) = State.XN(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.DK(i_) = State.DN(i_)
    Next i_
    State.Fold = State.F
    State.K = State.K + 1#
    GoTo lbl_6
lbl_7:
    Result = False
    MinCGIteration = Result
    Exit Function
    
    '
    ' Saving state
    '
lbl_rcomm:
    Result = True
    State.RState.IA(0#) = N
    State.RState.IA(1#) = i
    State.RState.IA(2#) = MCINFO
    State.RState.RA(0#) = BetaK
    State.RState.RA(1#) = V
    State.RState.RA(2#) = VV
    MinCGIteration = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Conjugate gradient results
'
'Called after MinCG returned False.
'
'INPUT PARAMETERS:
'    State   -   algorithm state (used by MinCGIteration).
'
'OUTPUT PARAMETERS:
'    X       -   array[0..N-1], solution
'    Rep     -   optimization report:
'                * Rep.TerminationType completetion code:
'                    * -2    rounding errors prevent further improvement.
'                            X contains best point found.
'                    * -1    incorrect parameters were specified
'                    *  1    relative function improvement is no more than
'                            EpsF.
'                    *  2    relative step is no more than EpsX.
'                    *  4    gradient norm is no more than EpsG
'                    *  5    MaxIts steps was taken
'                    *  7    stopping conditions are too stringent,
'                            further improvement is impossible
'                * Rep.IterationsCount contains iterations count
'                * NFEV countains number of function calculations
'
'  -- ALGLIB --
'     Copyright 20.04.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinCGResults(ByRef State As MinCGState, _
         ByRef X() As Double, _
         ByRef Rep As MinCGReport)
    Dim i_ As Long
    ReDim X(0# To State.N - 1#)
    For i_ = 0# To State.N - 1# Step 1
        X(i_) = State.XN(i_)
    Next i_
    Rep.IterationsCount = State.RepIterationsCount
    Rep.NFEV = State.RepNFEV
    Rep.TerminationType = State.RepTerminationType
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Clears request fileds (to be sure that we don't forgot to clear something)
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Sub ClearRequestFieldsCG(ByRef State As MinCGState)
    State.NeedFG = False
    State.XUpdated = False
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Copyright (c) 2009, Sergey Bochkanov (ALGLIB project).
'
'>>> SOURCE LICENSE >>>
'This program is free software; you can redistribute it and/or modify
'it under the terms of the GNU General Public License as published by
'the Free Software Foundation (www.fsf.org); either version 2 of the
'License, or (at your option) any later version.
'
'This program is distributed in the hope that it will be useful,
'but WITHOUT ANY WARRANTY; without even the implied warranty of
'MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
'GNU General Public License for more details.
'
'A copy of the GNU General Public License is available at
'http://www.fsf.org/licensing/licenses
'
'>>> END OF LICENSE >>>
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Routines
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'    LEVENBERG-MARQUARDT-LIKE METHOD FOR NON-LINEAR OPTIMIZATION
'
'Optimization using function gradient and Hessian.  Algorithm -  Levenberg-
'Marquardt   modification   with   L-BFGS   pre-optimization  and  internal
'pre-conditioned L-BFGS optimization after each Levenberg-Marquardt step.
'
'Function F has general form (not "sum-of-squares"):
'
'    F = F(x[0], ..., x[n-1])
'
'EXAMPLE
'
'See HTML-documentation.
'
'INPUT PARAMETERS:
'    N       -   dimension, N>1
'    X       -   initial solution, array[0..N-1]
'
'OUTPUT PARAMETERS:
'    State   -   structure which stores algorithm state between subsequent
'                calls of MinLMIteration. Used for reverse communication.
'                This structure should be passed to MinLMIteration subroutine.
'
'See also MinLMIteration, MinLMResults.
'
'NOTES:
'
'1. you may tune stopping conditions with MinLMSetCond() function
'2. if target function contains exp() or other fast growing functions,  and
'   optimization algorithm makes too large steps which leads  to  overflow,
'   use MinLMSetStpMax() function to bound algorithm's steps.
'
'  -- ALGLIB --
'     Copyright 30.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLMCreateFGH(ByRef N As Long, _
         ByRef X() As Double, _
         ByRef State As MinLMState)
    Dim i_ As Long
    
    '
    ' Prepare RComm
    '
    ReDim State.RState.IA(0# To 3#)
    ReDim State.RState.BA(0# To 0#)
    ReDim State.RState.RA(0# To 7#)
    State.RState.Stage = -1#
    
    '
    ' prepare internal structures
    '
    Call LMPrepare(N, 0#, True, State)
    
    '
    ' initialize, check parameters
    '
    Call MinLMSetCond(State, 0#, 0#, 0#, 0#)
    Call MinLMSetXRep(State, False)
    Call MinLMSetStpMax(State, 0#)
    State.N = N
    State.M = 0#
    State.Flags = 0#
    State.UserMode = LMModeFGH
    State.WrongParams = False
    If N < 1# Then
        State.WrongParams = True
        Exit Sub
    End If
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = X(i_)
    Next i_
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'    LEVENBERG-MARQUARDT-LIKE METHOD FOR NON-LINEAR OPTIMIZATION
'
'Optimization using function gradient and Jacobian.  Algorithm -  Levenberg-
'Marquardt   modification   with   L-BFGS   pre-optimization  and  internal
'pre-conditioned L-BFGS optimization after each Levenberg-Marquardt step.
'
'Function F is represented as sum of squares:
'
'    F = f[0]^2(x[0],...,x[n-1]) + ... + f[m-1]^2(x[0],...,x[n-1])
'
'EXAMPLE
'
'See HTML-documentation.
'
'INPUT PARAMETERS:
'    N       -   dimension, N>1
'    M       -   number of functions f[i]
'    X       -   initial solution, array[0..N-1]
'
'OUTPUT PARAMETERS:
'    State   -   structure which stores algorithm state between subsequent
'                calls of MinLMIteration. Used for reverse communication.
'                This structure should be passed to MinLMIteration subroutine.
'
'See also MinLMIteration, MinLMResults.
'
'NOTES:
'
'1. you may tune stopping conditions with MinLMSetCond() function
'2. if target function contains exp() or other fast growing functions,  and
'   optimization algorithm makes too large steps which leads  to  overflow,
'   use MinLMSetStpMax() function to bound algorithm's steps.
'
'  -- ALGLIB --
'     Copyright 30.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLMCreateFGJ(ByRef N As Long, _
         ByRef M As Long, _
         ByRef X() As Double, _
         ByRef State As MinLMState)
    Dim i_ As Long
    
    '
    ' Prepare RComm
    '
    ReDim State.RState.IA(0# To 3#)
    ReDim State.RState.BA(0# To 0#)
    ReDim State.RState.RA(0# To 7#)
    State.RState.Stage = -1#
    
    '
    ' prepare internal structures
    '
    Call LMPrepare(N, M, True, State)
    
    '
    ' initialize, check parameters
    '
    Call MinLMSetCond(State, 0#, 0#, 0#, 0#)
    Call MinLMSetXRep(State, False)
    Call MinLMSetStpMax(State, 0#)
    State.N = N
    State.M = M
    State.Flags = 0#
    State.UserMode = LMModeFGJ
    State.WrongParams = False
    If N < 1# Then
        State.WrongParams = True
        Exit Sub
    End If
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = X(i_)
    Next i_
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'    CLASSIC LEVENBERG-MARQUARDT METHOD FOR NON-LINEAR OPTIMIZATION
'
'Optimization using Jacobi matrix. Algorithm  -  classic Levenberg-Marquardt
'method.
'
'Function F is represented as sum of squares:
'
'    F = f[0]^2(x[0],...,x[n-1]) + ... + f[m-1]^2(x[0],...,x[n-1])
'
'EXAMPLE
'
'See HTML-documentation.
'
'INPUT PARAMETERS:
'    N       -   dimension, N>1
'    M       -   number of functions f[i]
'    X       -   initial solution, array[0..N-1]
'
'OUTPUT PARAMETERS:
'    State   -   structure which stores algorithm state between subsequent
'                calls of MinLMIteration. Used for reverse communication.
'                This structure should be passed to MinLMIteration subroutine.
'
'See also MinLMIteration, MinLMResults.
'
'NOTES:
'
'1. you may tune stopping conditions with MinLMSetCond() function
'2. if target function contains exp() or other fast growing functions,  and
'   optimization algorithm makes too large steps which leads  to  overflow,
'   use MinLMSetStpMax() function to bound algorithm's steps.
'
'  -- ALGLIB --
'     Copyright 30.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLMCreateFJ(ByRef N As Long, _
         ByRef M As Long, _
         ByRef X() As Double, _
         ByRef State As MinLMState)
    Dim i_ As Long
    
    '
    ' Prepare RComm
    '
    ReDim State.RState.IA(0# To 3#)
    ReDim State.RState.BA(0# To 0#)
    ReDim State.RState.RA(0# To 7#)
    State.RState.Stage = -1#
    
    '
    ' prepare internal structures
    '
    Call LMPrepare(N, M, True, State)
    
    '
    ' initialize, check parameters
    '
    Call MinLMSetCond(State, 0#, 0#, 0#, 0#)
    Call MinLMSetXRep(State, False)
    Call MinLMSetStpMax(State, 0#)
    State.N = N
    State.M = M
    State.Flags = 0#
    State.UserMode = LMModeFJ
    State.WrongParams = False
    If N < 1# Then
        State.WrongParams = True
        Exit Sub
    End If
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = X(i_)
    Next i_
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets stopping conditions for Levenberg-Marquardt optimization
'algorithm.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be initialized
'                with MinLMCreate???()
'    EpsG    -   >=0
'                The  subroutine  finishes  its  work   if   the  condition
'                ||G||<EpsG is satisfied, where ||.|| means Euclidian norm,
'                G - gradient.
'    EpsF    -   >=0
'                The  subroutine  finishes  its work if on k+1-th iteration
'                the  condition  |F(k+1)-F(k)|<=EpsF*max{|F(k)|,|F(k+1)|,1}
'                is satisfied.
'    EpsX    -   >=0
'                The subroutine finishes its work if  on  k+1-th  iteration
'                the condition |X(k+1)-X(k)| <= EpsX is fulfilled.
'    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
'                iterations   is    unlimited.   Only   Levenberg-Marquardt
'                iterations  are  counted  (L-BFGS/CG  iterations  are  NOT
'                counted  because their cost is very low copared to that of
'                LM).
'
'Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
'automatic stopping criterion selection (small EpsX).
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLMSetCond(ByRef State As MinLMState, _
         ByVal EpsG As Double, _
         ByVal EpsF As Double, _
         ByVal EpsX As Double, _
         ByVal MaxIts As Long)
    If EpsG = 0# And EpsF = 0# And EpsX = 0# And MaxIts = 0# Then
        EpsX = 0.000001
    End If
    State.EpsG = EpsG
    State.EpsF = EpsF
    State.EpsX = EpsX
    State.MaxIts = MaxIts
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function turns on/off reporting.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinLMCreate???()
'    NeedXRep-   whether iteration reports are needed or not
'
'Usually  algorithm  returns  from  MinLMIteration()  only  when  it  needs
'function/gradient/Hessian. However, with this function we can let it  stop
'after  each  iteration  (one iteration may include  more than one function
'evaluation), which is indicated by XUpdated field.
'
'Both Levenberg-Marquardt and L-BFGS iterations are reported.
'
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLMSetXRep(ByRef State As MinLMState, ByVal NeedXRep As Boolean)
    State.XRep = NeedXRep
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets maximum step length
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinCGCreate???()
'    StpMax  -   maximum step length, >=0. Set StpMax to 0.0,  if you don't
'                want to limit step length.
'
'Use this subroutine when you optimize target function which contains exp()
'or  other  fast  growing  functions,  and optimization algorithm makes too
'large  steps  which  leads  to overflow. This function allows us to reject
'steps  that  are  too  large  (and  therefore  expose  us  to the possible
'overflow) without actually calculating function value at the x+stp*d.
'
'NOTE: non-zero StpMax leads to moderate  performance  degradation  because
'intermediate  step  of  preconditioned L-BFGS optimization is incompatible
'with limits on step size.
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLMSetStpMax(ByRef State As MinLMState, ByVal StpMax As Double)
    State.StpMax = StpMax
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'One Levenberg-Marquardt iteration.
'
'Called after inialization of State structure with MinLMXXX subroutine.
'See HTML docs for examples.
'
'Input parameters:
'    State   -   structure which stores algorithm state between subsequent
'                calls and which is used for reverse communication. Must be
'                initialized with MinLMXXX call first.
'
'If subroutine returned False, iterative algorithm has converged.
'
'If subroutine returned True, then:
'* if State.NeedF=True,      -   function value F at State.X[0..N-1]
'                                is required
'* if State.NeedFG=True      -   function value F and gradient G
'                                are required
'* if State.NeedFiJ=True     -   function vector f[i] and Jacobi matrix J
'                                are required
'* if State.NeedFGH=True     -   function value F, gradient G and Hesian H
'                                are required
'* if State.XUpdated=True    -   algorithm reports about new iteration,
'                                State.X contains current point,
'                                State.F contains function value.
'
'One and only one of this fields can be set at time.
'
'Results are stored:
'* function value            -   in MinLMState.F
'* gradient                  -   in MinLMState.G[0..N-1]
'* Jacobi matrix             -   in MinLMState.J[0..M-1,0..N-1]
'* Hessian                   -   in MinLMState.H[0..N-1,0..N-1]
'
'  -- ALGLIB --
'     Copyright 10.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Function MinLMIteration(ByRef State As MinLMState) As Boolean
    Dim Result As Boolean
    Dim N As Long
    Dim M As Long
    Dim i As Long
    Dim StepNorm As Double
    Dim SPD As Boolean
    Dim FBase As Double
    Dim FNew As Double
    Dim Lambda As Double
    Dim Nu As Double
    Dim LambdaUp As Double
    Dim LambdaDown As Double
    Dim LBFGSFlags As Long
    Dim V As Double
    Dim i_ As Long
    
    '
    ' Reverse communication preparations
    ' I know it looks ugly, but it works the same way
    ' anywhere from C++ to Python.
    '
    ' This code initializes locals by:
    ' * random values determined during code
    '   generation - on first subroutine call
    ' * values from previous call - on subsequent calls
    '
    If State.RState.Stage >= 0# Then
        N = State.RState.IA(0#)
        M = State.RState.IA(1#)
        i = State.RState.IA(2#)
        LBFGSFlags = State.RState.IA(3#)
        SPD = State.RState.BA(0#)
        StepNorm = State.RState.RA(0#)
        FBase = State.RState.RA(1#)
        FNew = State.RState.RA(2#)
        Lambda = State.RState.RA(3#)
        Nu = State.RState.RA(4#)
        LambdaUp = State.RState.RA(5#)
        LambdaDown = State.RState.RA(6#)
        V = State.RState.RA(7#)
    Else
        N = -983#
        M = -989#
        i = -834#
        LBFGSFlags = 900#
        SPD = True
        StepNorm = 364#
        FBase = 214#
        FNew = -338#
        Lambda = -686#
        Nu = 912#
        LambdaUp = 585#
        LambdaDown = 497#
        V = -271#
    End If
    If State.RState.Stage = 0# Then
        GoTo lbl_0
    End If
    If State.RState.Stage = 1# Then
        GoTo lbl_1
    End If
    If State.RState.Stage = 2# Then
        GoTo lbl_2
    End If
    If State.RState.Stage = 3# Then
        GoTo lbl_3
    End If
    If State.RState.Stage = 4# Then
        GoTo lbl_4
    End If
    If State.RState.Stage = 5# Then
        GoTo lbl_5
    End If
    If State.RState.Stage = 6# Then
        GoTo lbl_6
    End If
    If State.RState.Stage = 7# Then
        GoTo lbl_7
    End If
    If State.RState.Stage = 8# Then
        GoTo lbl_8
    End If
    If State.RState.Stage = 9# Then
        GoTo lbl_9
    End If
    If State.RState.Stage = 10# Then
        GoTo lbl_10
    End If
    If State.RState.Stage = 11# Then
        GoTo lbl_11
    End If
    If State.RState.Stage = 12# Then
        GoTo lbl_12
    End If
    If State.RState.Stage = 13# Then
        GoTo lbl_13
    End If
    If State.RState.Stage = 14# Then
        GoTo lbl_14
    End If
    If State.RState.Stage = 15# Then
        GoTo lbl_15
    End If
    
    '
    ' Routine body
    '
    If State.WrongParams Then
        State.RepTerminationType = -1#
        Result = False
        MinLMIteration = Result
        Exit Function
    End If
    
    '
    ' prepare params
    '
    N = State.N
    M = State.M
    LambdaUp = 20#
    LambdaDown = 0.5
    Nu = 1#
    LBFGSFlags = 0#
    
    '
    ' if we have F and G
    '
    If Not ((State.UserMode = LMModeFGJ Or State.UserMode = LMModeFGH) And State.Flags \ LMFlagNoPreLBFGS Mod 2# = 0#) Then
        GoTo lbl_16
    End If
    
    '
    ' First stage of the hybrid algorithm: LBFGS
    '
    Call MinLBFGSCreate(N, MinInt(N, LMPreLBFGSM), State.X, State.InternalState)
    Call MinLBFGSSetCond(State.InternalState, 0#, 0#, 0#, MaxInt(5#, N))
    Call MinLBFGSSetXRep(State.InternalState, State.XRep)
    Call MinLBFGSSetStpMax(State.InternalState, State.StpMax)
lbl_18:
    If Not MinLBFGSIteration(State.InternalState) Then
        GoTo lbl_19
    End If
    If Not State.InternalState.NeedFG Then
        GoTo lbl_20
    End If
    
    '
    ' RComm
    '
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = State.InternalState.X(i_)
    Next i_
    Call LMClearRequestFields(State)
    State.NeedFG = True
    State.RState.Stage = 0#
    GoTo lbl_rcomm
lbl_0:
    State.RepNFunc = State.RepNFunc + 1#
    State.RepNGrad = State.RepNGrad + 1#
    
    '
    ' Call LBFGS
    '
    State.InternalState.F = State.F
    For i_ = 0# To N - 1# Step 1
        State.InternalState.G(i_) = State.G(i_)
    Next i_
lbl_20:
    If Not (State.InternalState.XUpdated And State.XRep) Then
        GoTo lbl_22
    End If
    Call LMClearRequestFields(State)
    State.F = State.InternalState.F
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = State.InternalState.X(i_)
    Next i_
    State.XUpdated = True
    State.RState.Stage = 1#
    GoTo lbl_rcomm
lbl_1:
lbl_22:
    GoTo lbl_18
lbl_19:
    Call MinLBFGSResults(State.InternalState, State.X, State.InternalRep)
    GoTo lbl_17
lbl_16:
    
    '
    ' No first stage.
    ' However, we may need to report initial point
    '
    If Not State.XRep Then
        GoTo lbl_24
    End If
    Call LMClearRequestFields(State)
    State.NeedF = True
    State.RState.Stage = 2#
    GoTo lbl_rcomm
lbl_2:
    Call LMClearRequestFields(State)
    State.XUpdated = True
    State.RState.Stage = 3#
    GoTo lbl_rcomm
lbl_3:
lbl_24:
lbl_17:
    
    '
    ' Second stage of the hybrid algorithm: LM
    ' Initialize quadratic model.
    '
    If State.UserMode <> LMModeFGH Then
        GoTo lbl_26
    End If
    
    '
    ' RComm
    '
    Call LMClearRequestFields(State)
    State.NeedFGH = True
    State.RState.Stage = 4#
    GoTo lbl_rcomm
lbl_4:
    State.RepNFunc = State.RepNFunc + 1#
    State.RepNGrad = State.RepNGrad + 1#
    State.RepNHess = State.RepNHess + 1#
    
    '
    ' generate raw quadratic model
    '
    Call RMatrixCopy(N, N, State.H, 0#, 0#, State.RawModel, 0#, 0#)
    For i_ = 0# To N - 1# Step 1
        State.GBase(i_) = State.G(i_)
    Next i_
    FBase = State.F
lbl_26:
    If Not (State.UserMode = LMModeFGJ Or State.UserMode = LMModeFJ) Then
        GoTo lbl_28
    End If
    
    '
    ' RComm
    '
    Call LMClearRequestFields(State)
    State.NeedFiJ = True
    State.RState.Stage = 5#
    GoTo lbl_rcomm
lbl_5:
    State.RepNFunc = State.RepNFunc + 1#
    State.RepNJac = State.RepNJac + 1#
    
    '
    ' generate raw quadratic model
    '
    Call RMatrixGEMM(N, N, M, 2#, State.j, 0#, 0#, 1#, State.j, 0#, 0#, 0#, 0#, State.RawModel, 0#, 0#)
    Call RMatrixMV(N, M, State.j, 0#, 0#, 1#, State.FI, 0#, State.GBase, 0#)
    For i_ = 0# To N - 1# Step 1
        State.GBase(i_) = 2 * State.GBase(i_)
    Next i_
    FBase = 0#
    For i_ = 0# To M - 1# Step 1
        FBase = FBase + State.FI(i_) * State.FI(i_)
    Next i_
lbl_28:
    Lambda = 0.001
lbl_30:
    If False Then
        GoTo lbl_31
    End If
    
    '
    ' 1. Model = RawModel+lambda*I
    ' 2. Try to solve (RawModel+Lambda*I)*dx = -g.
    '    Increase lambda if left part is not positive definite.
    '
    For i = 0# To N - 1# Step 1
        For i_ = 0# To N - 1# Step 1
            State.Model(i, i_) = State.RawModel(i, i_)
        Next i_
        State.Model(i, i) = State.Model(i, i) + Lambda
    Next i
    SPD = SPDMatrixCholesky(State.Model, N, True)
    State.RepNCholesky = State.RepNCholesky + 1#
    If SPD Then
        GoTo lbl_32
    End If
    If Not IncreaseLambda(Lambda, Nu, LambdaUp) Then
        GoTo lbl_34
    End If
    GoTo lbl_30
    GoTo lbl_35
lbl_34:
    State.RepTerminationType = 7#
    Call LMClearRequestFields(State)
    State.NeedF = True
    State.RState.Stage = 6#
    GoTo lbl_rcomm
lbl_6:
    GoTo lbl_31
lbl_35:
lbl_32:
    Call SPDMatrixCholeskySolve(State.Model, N, True, State.GBase, State.SolverInfo, State.SolverRep, State.XDir)
    If State.SolverInfo >= 0# Then
        GoTo lbl_36
    End If
    If Not IncreaseLambda(Lambda, Nu, LambdaUp) Then
        GoTo lbl_38
    End If
    GoTo lbl_30
    GoTo lbl_39
lbl_38:
    State.RepTerminationType = 7#
    Call LMClearRequestFields(State)
    State.NeedF = True
    State.RState.Stage = 7#
    GoTo lbl_rcomm
lbl_7:
    GoTo lbl_31
lbl_39:
lbl_36:
    For i_ = 0# To N - 1# Step 1
        State.XDir(i_) = -1 * State.XDir(i_)
    Next i_
    
    '
    ' Candidate lambda is found.
    ' 1. Save old w in WBase
    ' 1. Test some stopping criterions
    ' 2. If error(w+wdir)>error(w), increase lambda
    '
    For i_ = 0# To N - 1# Step 1
        State.XPrev(i_) = State.X(i_)
    Next i_
    State.FPrev = State.F
    For i_ = 0# To N - 1# Step 1
        State.XBase(i_) = State.X(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = State.X(i_) + State.XDir(i_)
    Next i_
    StepNorm = 0#
    For i_ = 0# To N - 1# Step 1
        StepNorm = StepNorm + State.XDir(i_) * State.XDir(i_)
    Next i_
    StepNorm = Sqr(StepNorm)
    If Not (State.StpMax > 0# And StepNorm > State.StpMax) Then
        GoTo lbl_40
    End If
    
    '
    ' Step is larger than the limit,
    ' larger lambda is needed
    '
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = State.XBase(i_)
    Next i_
    If Not IncreaseLambda(Lambda, Nu, LambdaUp) Then
        GoTo lbl_42
    End If
    GoTo lbl_30
    GoTo lbl_43
lbl_42:
    State.RepTerminationType = 7#
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = State.XPrev(i_)
    Next i_
    Call LMClearRequestFields(State)
    State.NeedF = True
    State.RState.Stage = 8#
    GoTo lbl_rcomm
lbl_8:
    GoTo lbl_31
lbl_43:
lbl_40:
    Call LMClearRequestFields(State)
    State.NeedF = True
    State.RState.Stage = 9#
    GoTo lbl_rcomm
lbl_9:
    State.RepNFunc = State.RepNFunc + 1#
    FNew = State.F
    If FNew <= FBase Then
        GoTo lbl_44
    End If
    
    '
    ' restore state and continue search for lambda
    '
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = State.XBase(i_)
    Next i_
    If Not IncreaseLambda(Lambda, Nu, LambdaUp) Then
        GoTo lbl_46
    End If
    GoTo lbl_30
    GoTo lbl_47
lbl_46:
    State.RepTerminationType = 7#
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = State.XPrev(i_)
    Next i_
    Call LMClearRequestFields(State)
    State.NeedF = True
    State.RState.Stage = 10#
    GoTo lbl_rcomm
lbl_10:
    GoTo lbl_31
lbl_47:
lbl_44:
    If Not (State.StpMax = 0# And (State.UserMode = LMModeFGJ Or State.UserMode = LMModeFGH) And State.Flags \ LMFlagNoIntLBFGS Mod 2# = 0#) Then
        GoTo lbl_48
    End If
    
    '
    ' Optimize using LBFGS, with inv(cholesky(H)) as preconditioner.
    '
    ' It is possible only when StpMax=0, because we can't guarantee
    ' that step remains bounded when preconditioner is used (we need
    ' SVD decomposition to do that, which is too slow).
    '
    Call RMatrixTRInverse(State.Model, N, True, False, State.InvInfo, State.InvRep)
    If State.InvInfo <= 0# Then
        GoTo lbl_50
    End If
    
    '
    ' if matrix can be inverted, use it.
    ' just silently move to next iteration otherwise.
    ' (will be very, very rare, mostly for specially
    ' designed near-degenerate tasks)
    '
    For i_ = 0# To N - 1# Step 1
        State.XBase(i_) = State.X(i_)
    Next i_
    For i = 0# To N - 1# Step 1
        State.XPrec(i) = 0#
    Next i
    Call MinLBFGSCreateX(N, MinInt(N, LMIntLBFGSIts), State.XPrec, LBFGSFlags, State.InternalState)
    Call MinLBFGSSetCond(State.InternalState, 0#, 0#, 0#, LMIntLBFGSIts)
lbl_52:
    If Not MinLBFGSIteration(State.InternalState) Then
        GoTo lbl_53
    End If
    
    '
    ' convert XPrec to unpreconditioned form, then call RComm.
    '
    For i = 0# To N - 1# Step 1
        V = 0#
        For i_ = i To N - 1# Step 1
            V = V + State.InternalState.X(i_) * State.Model(i, i_)
        Next i_
        State.X(i) = State.XBase(i) + V
    Next i
    Call LMClearRequestFields(State)
    State.NeedFG = True
    State.RState.Stage = 11#
    GoTo lbl_rcomm
lbl_11:
    State.RepNFunc = State.RepNFunc + 1#
    State.RepNGrad = State.RepNGrad + 1#
    
    '
    ' 1. pass State.F to State.InternalState.F
    ' 2. convert gradient back to preconditioned form
    '
    State.InternalState.F = State.F
    For i = 0# To N - 1# Step 1
        State.InternalState.G(i) = 0#
    Next i
    For i = 0# To N - 1# Step 1
        V = State.G(i)
        For i_ = i To N - 1# Step 1
            State.InternalState.G(i_) = State.InternalState.G(i_) + V * State.Model(i, i_)
        Next i_
    Next i
    
    '
    ' next iteration
    '
    GoTo lbl_52
lbl_53:
    
    '
    ' change LBFGS flags to NoRealloc.
    ' L-BFGS subroutine will use memory allocated from previous run.
    ' it is possible since all subsequent calls will be with same N/M.
    '
    LBFGSFlags = LBFGSNoRealloc
    
    '
    ' back to unpreconditioned X
    '
    Call MinLBFGSResults(State.InternalState, State.XPrec, State.InternalRep)
    For i = 0# To N - 1# Step 1
        V = 0#
        For i_ = i To N - 1# Step 1
            V = V + State.XPrec(i_) * State.Model(i, i_)
        Next i_
        State.X(i) = State.XBase(i) + V
    Next i
lbl_50:
lbl_48:
    
    '
    ' Composite iteration is almost over:
    ' * accept new position.
    ' * rebuild quadratic model
    '
    State.RepIterationsCount = State.RepIterationsCount + 1#
    If State.UserMode <> LMModeFGH Then
        GoTo lbl_54
    End If
    Call LMClearRequestFields(State)
    State.NeedFGH = True
    State.RState.Stage = 12#
    GoTo lbl_rcomm
lbl_12:
    State.RepNFunc = State.RepNFunc + 1#
    State.RepNGrad = State.RepNGrad + 1#
    State.RepNHess = State.RepNHess + 1#
    Call RMatrixCopy(N, N, State.H, 0#, 0#, State.RawModel, 0#, 0#)
    For i_ = 0# To N - 1# Step 1
        State.GBase(i_) = State.G(i_)
    Next i_
    FNew = State.F
lbl_54:
    If Not (State.UserMode = LMModeFGJ Or State.UserMode = LMModeFJ) Then
        GoTo lbl_56
    End If
    Call LMClearRequestFields(State)
    State.NeedFiJ = True
    State.RState.Stage = 13#
    GoTo lbl_rcomm
lbl_13:
    State.RepNFunc = State.RepNFunc + 1#
    State.RepNJac = State.RepNJac + 1#
    Call RMatrixGEMM(N, N, M, 2#, State.j, 0#, 0#, 1#, State.j, 0#, 0#, 0#, 0#, State.RawModel, 0#, 0#)
    Call RMatrixMV(N, M, State.j, 0#, 0#, 1#, State.FI, 0#, State.GBase, 0#)
    For i_ = 0# To N - 1# Step 1
        State.GBase(i_) = 2 * State.GBase(i_)
    Next i_
    FNew = 0#
    For i_ = 0# To M - 1# Step 1
        FNew = FNew + State.FI(i_) * State.FI(i_)
    Next i_
lbl_56:
    
    '
    ' Stopping conditions
    '
    For i_ = 0# To N - 1# Step 1
        State.WORK(i_) = State.XPrev(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.WORK(i_) = State.WORK(i_) - State.X(i_)
    Next i_
    StepNorm = 0#
    For i_ = 0# To N - 1# Step 1
        StepNorm = StepNorm + State.WORK(i_) * State.WORK(i_)
    Next i_
    StepNorm = Sqr(StepNorm)
    If StepNorm <= State.EpsX Then
        State.RepTerminationType = 2#
        GoTo lbl_31
    End If
    If State.RepIterationsCount >= State.MaxIts And State.MaxIts > 0# Then
        State.RepTerminationType = 5#
        GoTo lbl_31
    End If
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.GBase(i_) * State.GBase(i_)
    Next i_
    V = Sqr(V)
    If V <= State.EpsG Then
        State.RepTerminationType = 4#
        GoTo lbl_31
    End If
    If Abs(FNew - FBase) <= State.EpsF * MaxReal(1#, MaxReal(Abs(FNew), Abs(FBase))) Then
        State.RepTerminationType = 1#
        GoTo lbl_31
    End If
    
    '
    ' Now, iteration is finally over:
    ' * update FBase
    ' * decrease lambda
    ' * report new iteration
    '
    If Not State.XRep Then
        GoTo lbl_58
    End If
    Call LMClearRequestFields(State)
    State.XUpdated = True
    State.F = FNew
    State.RState.Stage = 14#
    GoTo lbl_rcomm
lbl_14:
lbl_58:
    FBase = FNew
    Call DecreaseLambda(Lambda, Nu, LambdaDown)
    GoTo lbl_30
lbl_31:
    
    '
    ' final point is reported
    '
    If Not State.XRep Then
        GoTo lbl_60
    End If
    Call LMClearRequestFields(State)
    State.XUpdated = True
    State.F = FNew
    State.RState.Stage = 15#
    GoTo lbl_rcomm
lbl_15:
lbl_60:
    Result = False
    MinLMIteration = Result
    Exit Function
    
    '
    ' Saving state
    '
lbl_rcomm:
    Result = True
    State.RState.IA(0#) = N
    State.RState.IA(1#) = M
    State.RState.IA(2#) = i
    State.RState.IA(3#) = LBFGSFlags
    State.RState.BA(0#) = SPD
    State.RState.RA(0#) = StepNorm
    State.RState.RA(1#) = FBase
    State.RState.RA(2#) = FNew
    State.RState.RA(3#) = Lambda
    State.RState.RA(4#) = Nu
    State.RState.RA(5#) = LambdaUp
    State.RState.RA(6#) = LambdaDown
    State.RState.RA(7#) = V
    MinLMIteration = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Levenberg-Marquardt algorithm results
'
'Called after MinLMIteration returned False.
'
'Input parameters:
'    State   -   algorithm state (used by MinLMIteration).
'
'Output parameters:
'    X       -   array[0..N-1], solution
'    Rep     -   optimization report:
'                * Rep.TerminationType completetion code:
'                    * -1    incorrect parameters were specified
'                    *  1    relative function improvement is no more than
'                            EpsF.
'                    *  2    relative step is no more than EpsX.
'                    *  4    gradient is no more than EpsG.
'                    *  5    MaxIts steps was taken
'                    *  7    stopping conditions are too stringent,
'                            further improvement is impossible
'                * Rep.IterationsCount contains iterations count
'                * Rep.NFunc     - number of function calculations
'                * Rep.NJac      - number of Jacobi matrix calculations
'                * Rep.NGrad     - number of gradient calculations
'                * Rep.NHess     - number of Hessian calculations
'                * Rep.NCholesky - number of Cholesky decomposition calculations
'
'  -- ALGLIB --
'     Copyright 10.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLMResults(ByRef State As MinLMState, _
         ByRef X() As Double, _
         ByRef Rep As MinLMReport)
    Dim i_ As Long
    ReDim X(0# To State.N - 1#)
    For i_ = 0# To State.N - 1# Step 1
        X(i_) = State.X(i_)
    Next i_
    Rep.IterationsCount = State.RepIterationsCount
    Rep.TerminationType = State.RepTerminationType
    Rep.NFunc = State.RepNFunc
    Rep.NJac = State.RepNJac
    Rep.NGrad = State.RepNGrad
    Rep.NHess = State.RepNHess
    Rep.NCholesky = State.RepNCholesky
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Prepare internal structures (except for RComm).
'
'Note: M must be zero for FGH mode, non-zero for FJ/FGJ mode.
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Sub LMPrepare(ByVal N As Long, _
         ByVal M As Long, _
         ByVal HaveGrad As Boolean, _
         ByRef State As MinLMState)
    State.RepIterationsCount = 0#
    State.RepTerminationType = 0#
    State.RepNFunc = 0#
    State.RepNJac = 0#
    State.RepNGrad = 0#
    State.RepNHess = 0#
    State.RepNCholesky = 0#
    If N <= 0# Or M < 0# Then
        Exit Sub
    End If
    If HaveGrad Then
        ReDim State.G(0# To N - 1#)
    End If
    If M <> 0# Then
        ReDim State.j(0# To M - 1#, 0# To N - 1#)
        ReDim State.FI(0# To M - 1#)
        ReDim State.H(0# To 0#, 0# To 0#)
    Else
        ReDim State.j(0# To 0#, 0# To 0#)
        ReDim State.FI(0# To 0#)
        ReDim State.H(0# To N - 1#, 0# To N - 1#)
    End If
    ReDim State.X(0# To N - 1#)
    ReDim State.RawModel(0# To N - 1#, 0# To N - 1#)
    ReDim State.Model(0# To N - 1#, 0# To N - 1#)
    ReDim State.XBase(0# To N - 1#)
    ReDim State.XPrec(0# To N - 1#)
    ReDim State.GBase(0# To N - 1#)
    ReDim State.XDir(0# To N - 1#)
    ReDim State.XPrev(0# To N - 1#)
    ReDim State.WORK(0# To MaxInt(N, M))
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Clears request fileds (to be sure that we don't forgot to clear something)
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Sub LMClearRequestFields(ByRef State As MinLMState)
    State.NeedF = False
    State.NeedFG = False
    State.NeedFGH = False
    State.NeedFiJ = False
    State.XUpdated = False
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Increases lambda, returns False when there is a danger of overflow
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Function IncreaseLambda(ByRef Lambda As Double, _
         ByRef Nu As Double, _
         ByVal LambdaUp As Double) As Boolean
    Dim Result As Boolean
    Dim LnLambda As Double
    Dim LnNu As Double
    Dim LnLambdaUp As Double
    Dim LnMax As Double
    Result = False
    LnLambda = log(Lambda)
    LnLambdaUp = log(LambdaUp)
    LnNu = log(Nu)
    LnMax = log(MaxRealNumber)
    If LnLambda + LnLambdaUp + LnNu > LnMax Then
        IncreaseLambda = Result
        Exit Function
    End If
    If LnNu + log(2#) > LnMax Then
        IncreaseLambda = Result
        Exit Function
    End If
    Lambda = Lambda * LambdaUp * Nu
    Nu = Nu * 2#
    Result = True
    IncreaseLambda = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Decreases lambda, but leaves it unchanged when there is danger of underflow.
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Sub DecreaseLambda(ByRef Lambda As Double, _
         ByRef Nu As Double, _
         ByVal LambdaDown As Double)
    Nu = 1#
    If log(Lambda) + log(LambdaDown) < log(MinRealNumber) Then
        Lambda = MinRealNumber
    Else
        Lambda = Lambda * LambdaDown
    End If
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Copyright (c) 2007-2008, Sergey Bochkanov (ALGLIB project).
'
'>>> SOURCE LICENSE >>>
'This program is free software; you can redistribute it and/or modify
'it under the terms of the GNU General Public License as published by
'the Free Software Foundation (www.fsf.org); either version 2 of the
'License, or (at your option) any later version.
'
'This program is distributed in the hope that it will be useful,
'but WITHOUT ANY WARRANTY; without even the implied warranty of
'MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
'GNU General Public License for more details.
'
'A copy of the GNU General Public License is available at
'http://www.fsf.org/licensing/licenses
'
'>>> END OF LICENSE >>>
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Routines
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'        LIMITED MEMORY BFGS METHOD FOR LARGE SCALE OPTIMIZATION
'
'The subroutine minimizes function F(x) of N arguments by  using  a  quasi-
'Newton method (LBFGS scheme) which is optimized to use  a  minimum  amount
'of memory.
'
'The subroutine generates the approximation of an inverse Hessian matrix by
'using information about the last M steps of the algorithm  (instead of N).
'It lessens a required amount of memory from a value  of  order  N^2  to  a
'value of order 2*N*M.
'
'INPUT PARAMETERS:
'    N       -   problem dimension. N>0
'    M       -   number of corrections in the BFGS scheme of Hessian
'                approximation update. Recommended value:  3<=M<=7. The smaller
'                value causes worse convergence, the bigger will  not  cause  a
'                considerably better convergence, but will cause a fall in  the
'                performance. M<=N.
'    X       -   initial solution approximation, array[0..N-1].
'
'OUTPUT PARAMETERS:
'    State   -   structure used for reverse communication.
'
'This function  initializes  State   structure  with  default  optimization
'parameters (stopping conditions, step size, etc.). Use MinLBFGSSet??????()
'functions to tune optimization parameters.
'
'After   all   optimization   parameters   are   tuned,   you   should  use
'MinLBFGSIteration() function to advance algorithm iterations.
'
'NOTES:
'
'1. you may tune stopping conditions with MinLBFGSSetCond() function
'2. if target function contains exp() or other fast growing functions,  and
'   optimization algorithm makes too large steps which leads  to  overflow,
'   use MinLBFGSSetStpMax() function to bound algorithm's  steps.  However,
'   L-BFGS rarely needs such a tuning.
'
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLBFGSCreate(ByVal N As Long, _
         ByVal M As Long, _
         ByRef X() As Double, _
         ByRef State As MinLBFGSState)
    Call MinLBFGSCreateX(N, M, X, 0#, State)
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets stopping conditions for L-BFGS optimization algorithm.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be initialized
'                with MinLBFGSCreate()
'    EpsG    -   >=0
'                The  subroutine  finishes  its  work   if   the  condition
'                ||G||<EpsG is satisfied, where ||.|| means Euclidian norm,
'                G - gradient.
'    EpsF    -   >=0
'                The  subroutine  finishes  its work if on k+1-th iteration
'                the  condition  |F(k+1)-F(k)|<=EpsF*max{|F(k)|,|F(k+1)|,1}
'                is satisfied.
'    EpsX    -   >=0
'                The subroutine finishes its work if  on  k+1-th  iteration
'                the condition |X(k+1)-X(k)| <= EpsX is fulfilled.
'    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
'                iterations is unlimited.
'
'Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
'automatic stopping criterion selection (small EpsX).
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLBFGSSetCond(ByRef State As MinLBFGSState, _
         ByVal EpsG As Double, _
         ByVal EpsF As Double, _
         ByVal EpsX As Double, _
         ByVal MaxIts As Long)
    If EpsG = 0# And EpsF = 0# And EpsX = 0# And MaxIts = 0# Then
        EpsX = 0.000001
    End If
    State.EpsG = EpsG
    State.EpsF = EpsF
    State.EpsX = EpsX
    State.MaxIts = MaxIts
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function turns on/off reporting.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinLBFGSCreate()
'    NeedXRep-   whether iteration reports are needed or not
'
'Usually algorithm returns  from  MinLBFGSIteration()  only when  it  needs
'function/gradient/ (which is indicated by NeedFG field. However, with this
'function we can let it  stop  after  each  iteration  (one  iteration  may
'include more than one function evaluation), which is indicated by XUpdated
'field.
'
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLBFGSSetXRep(ByRef State As MinLBFGSState, _
         ByVal NeedXRep As Boolean)
    State.XRep = NeedXRep
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'This function sets maximum step length
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be
'                initialized with MinLBFGSCreate()
'    StpMax  -   maximum step length, >=0. Set StpMax to 0.0,  if you don't
'                want to limit step length.
'
'Use this subroutine when you optimize target function which contains exp()
'or  other  fast  growing  functions,  and optimization algorithm makes too
'large  steps  which  leads  to overflow. This function allows us to reject
'steps  that  are  too  large  (and  therefore  expose  us  to the possible
'overflow) without actually calculating function value at the x+stp*d.
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLBFGSSetStpMax(ByRef State As MinLBFGSState, _
         ByVal StpMax As Double)
    State.StpMax = StpMax
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Extended subroutine for internal use only.
'
'Accepts additional parameters:
'
'    Flags - additional settings:
'            * Flags = 0     means no additional settings
'            * Flags = 1     "do not allocate memory". used when solving
'                            a many subsequent tasks with  same N/M  values.
'                            First  call MUST  be without this flag bit set,
'                            subsequent  calls   of   MinLBFGS   with   same
'                            MinLBFGSState structure can set Flags to 1.
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLBFGSCreateX(ByVal N As Long, _
         ByVal M As Long, _
         ByRef X() As Double, _
         ByVal Flags As Long, _
         ByRef State As MinLBFGSState)
    Dim AllocateMem As Boolean
    Dim i_ As Long
    '
    ' Initialize
    '
    State.N = N
    State.M = M
    State.Flags = Flags
    AllocateMem = Flags Mod 2# = 0#
    Flags = Flags \ 2#
    If AllocateMem Then
        ReDim State.Rho(0# To M - 1#)
        ReDim State.Theta(0# To M - 1#)
        ReDim State.y(0# To M - 1#, 0# To N - 1#)
        ReDim State.S(0# To M - 1#, 0# To N - 1#)
        ReDim State.D(0# To N - 1#)
        ReDim State.X(0# To N - 1#)
        ReDim State.G(0# To N - 1#)
        ReDim State.WORK(0# To N - 1#)
    End If
    Call MinLBFGSSetCond(State, 0#, 0#, 0#, 0#)
    Call MinLBFGSSetXRep(State, False)
    Call MinLBFGSSetStpMax(State, 0#)
    '
    ' Prepare first run
    '
    State.K = 0#
    For i_ = 0# To N - 1# Step 1
        State.X(i_) = X(i_)
    Next i_
    ReDim State.RState.IA(0# To 6#)
    ReDim State.RState.RA(0# To 4#)
    State.RState.Stage = -1#
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'L-BFGS iterations
'
'Called after initialization with MinLBFGSCreate() function.
'
'INPUT PARAMETERS:
'    State   -   structure which stores algorithm state between calls and
'                which is used for reverse communication. Must be initialized
'                with MinLBFGSCreate()
'
'RESULT:
'* if function returned False, iterative proces has converged.
'  Use MinLBFGSResults() to obtain optimization results.
'* if subroutine returned True, then, depending on structure fields, we
'  have one of the following situations
'
'
'=== FUNC/GRAD REQUEST ===
'State.NeedFG is True => function value/gradient are needed.
'Caller should calculate function value State.F and gradient
'State.G[0..N-1] at State.X[0..N-1] and call MinLBFGSIteration() again.
'
'=== NEW INTERATION IS REPORTED ===
'State.XUpdated is True => one more iteration was made.
'State.X contains current position, State.F contains function value at X.
'You can read info from these fields, but never modify  them  because  they
'contain the only copy of optimization algorithm state.
'
'
'One and only one of these fields (NeedFG, XUpdated) is true on return. New
'iterations are reported only when reports  are  explicitly  turned  on  by
'MinLBFGSSetXRep() function, so if you never called it, you can expect that
'NeedFG is always True.
'
'
'  -- ALGLIB --
'     Copyright 20.03.2009 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Function MinLBFGSIteration(ByRef State As MinLBFGSState) As Boolean
    Dim Result As Boolean
    Dim N As Long
    Dim M As Long
    Dim MaxIts As Long
    Dim EpsF As Double
    Dim EpsG As Double
    Dim EpsX As Double
    Dim i As Long
    Dim j As Long
    Dim IC As Long
    Dim MCINFO As Long
    Dim V As Double
    Dim VV As Double
    Dim i_ As Long
    '
    ' Reverse communication preparations
    ' I know it looks ugly, but it works the same way
    ' anywhere from C++ to Python.
    '
    ' This code initializes locals by:
    ' * random values determined during code
    '   generation - on first subroutine call
    ' * values from previous call - on subsequent calls
    '
    If State.RState.Stage >= 0# Then
        N = State.RState.IA(0#)
        M = State.RState.IA(1#)
        MaxIts = State.RState.IA(2#)
        i = State.RState.IA(3#)
        j = State.RState.IA(4#)
        IC = State.RState.IA(5#)
        MCINFO = State.RState.IA(6#)
        EpsF = State.RState.RA(0#)
        EpsG = State.RState.RA(1#)
        EpsX = State.RState.RA(2#)
        V = State.RState.RA(3#)
        VV = State.RState.RA(4#)
    Else
        N = -983#
        M = -989#
        MaxIts = -834#
        i = 900#
        j = -287#
        IC = 364#
        MCINFO = 214#
        EpsF = -338#
        EpsG = -686#
        EpsX = 912#
        V = 585#
        VV = 497#
    End If
    If State.RState.Stage = 0# Then
        GoTo lbl_0
    End If
    If State.RState.Stage = 1# Then
        GoTo lbl_1
    End If
    If State.RState.Stage = 2# Then
        GoTo lbl_2
    End If
    If State.RState.Stage = 3# Then
        GoTo lbl_3
    End If
    '
    ' Routine body
    '
    '
    ' Unload frequently used variables from State structure
    ' (just for typing convinience)
    '
    N = State.N
    M = State.M
    EpsG = State.EpsG
    EpsF = State.EpsF
    EpsX = State.EpsX
    MaxIts = State.MaxIts
    State.RepTerminationType = 0#
    State.RepIterationsCount = 0#
    State.RepNFEV = 0#
    '
    ' Calculate F/G at the initial point
    '
    Call ClearRequestFieldsLBFGS(State)
    State.NeedFG = True
    State.RState.Stage = 0#
    GoTo lbl_rcomm
lbl_0:
    If Not State.XRep Then
        GoTo lbl_4
    End If
    Call ClearRequestFieldsLBFGS(State)
    State.XUpdated = True
    State.RState.Stage = 1#
    GoTo lbl_rcomm
lbl_1:
lbl_4:
    State.RepNFEV = 1#
    State.Fold = State.F
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.G(i_) * State.G(i_)
    Next i_
    V = Sqr(V)
    If V <= EpsG Then
        State.RepTerminationType = 4#
        Result = False
        MinLBFGSIteration = Result
        Exit Function
    End If
    '
    ' Choose initial step
    '
    If State.StpMax = 0# Then
        State.Stp = MinReal(1# / V, 1#)
    Else
        State.Stp = MinReal(1# / V, State.StpMax)
    End If
    For i_ = 0# To N - 1# Step 1
        State.D(i_) = -State.G(i_)
    Next i_
    '
    ' Main cycle
    '
lbl_6:
    If False Then
        GoTo lbl_7
    End If
    '
    ' Main cycle: prepare to 1-D line search
    '
    State.p = State.K Mod M
    State.q = MinInt(State.K, M - 1#)
    '
    ' Store X[k], G[k]
    '
    For i_ = 0# To N - 1# Step 1
        State.S(State.p, i_) = -State.X(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.y(State.p, i_) = -State.G(i_)
    Next i_
    '
    ' Minimize F(x+alpha*d)
    ' Calculate S[k], Y[k]
    '
    State.MCStage = 0#
    If State.K <> 0# Then
        State.Stp = 1#
    End If
    Call LinMinNormalizeD(State.D, State.Stp, N)
    Call MCSRCH(N, State.X, State.F, State.G, State.D, State.Stp, State.StpMax, MCINFO, State.NFEV, State.WORK, State.LState, State.MCStage)
lbl_8:
    If State.MCStage = 0# Then
        GoTo lbl_9
    End If
    Call ClearRequestFieldsLBFGS(State)
    State.NeedFG = True
    State.RState.Stage = 2#
    GoTo lbl_rcomm
lbl_2:
    Call MCSRCH(N, State.X, State.F, State.G, State.D, State.Stp, State.StpMax, MCINFO, State.NFEV, State.WORK, State.LState, State.MCStage)
    GoTo lbl_8
lbl_9:
    If Not State.XRep Then
        GoTo lbl_10
    End If
    '
    ' report
    '
    Call ClearRequestFieldsLBFGS(State)
    State.XUpdated = True
    State.RState.Stage = 3#
    GoTo lbl_rcomm
lbl_3:
lbl_10:
    State.RepNFEV = State.RepNFEV + State.NFEV
    State.RepIterationsCount = State.RepIterationsCount + 1#
    For i_ = 0# To N - 1# Step 1
        State.S(State.p, i_) = State.S(State.p, i_) + State.X(i_)
    Next i_
    For i_ = 0# To N - 1# Step 1
        State.y(State.p, i_) = State.y(State.p, i_) + State.G(i_)
    Next i_
    '
    ' Stopping conditions
    '
    If State.RepIterationsCount >= MaxIts And MaxIts > 0# Then
        '
        ' Too many iterations
        '
        State.RepTerminationType = 5#
        Result = False
        MinLBFGSIteration = Result
        Exit Function
    End If
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.G(i_) * State.G(i_)
    Next i_
    If Sqr(V) <= EpsG Then
        '
        ' Gradient is small enough
        '
        State.RepTerminationType = 4#
        Result = False
        MinLBFGSIteration = Result
        Exit Function
    End If
    If State.Fold - State.F <= EpsF * MaxReal(Abs(State.Fold), MaxReal(Abs(State.F), 1#)) Then
        '
        ' F(k+1)-F(k) is small enough
        '
        State.RepTerminationType = 1#
        Result = False
        MinLBFGSIteration = Result
        Exit Function
    End If
    V = 0#
    For i_ = 0# To N - 1# Step 1
        V = V + State.S(State.p, i_) * State.S(State.p, i_)
    Next i_
    If Sqr(V) <= EpsX Then
        '
        ' X(k+1)-X(k) is small enough
        '
        State.RepTerminationType = 2#
        Result = False
        MinLBFGSIteration = Result
        Exit Function
    End If
    '
    ' If Wolfe conditions are satisfied, we can update
    ' limited memory model.
    '
    ' However, if conditions are not satisfied (NFEV limit is met,
    ' function is too wild, ...), we'll skip L-BFGS update
    '
    If MCINFO <> 1# Then
        '
        ' Skip update.
        '
        ' In such cases we'll initialize search direction by
        ' antigradient vector, because it  leads to more
        ' transparent code with less number of special cases
        '
        State.Fold = State.F
        For i_ = 0# To N - 1# Step 1
            State.D(i_) = -State.G(i_)
        Next i_
    Else
        '
        ' Calculate Rho[k], GammaK
        '
        V = 0#
        For i_ = 0# To N - 1# Step 1
            V = V + State.y(State.p, i_) * State.S(State.p, i_)
        Next i_
        VV = 0#
        For i_ = 0# To N - 1# Step 1
            VV = VV + State.y(State.p, i_) * State.y(State.p, i_)
        Next i_
        If V = 0# Or VV = 0# Then
            '
            ' Rounding errors make further iterations impossible.
            '
            State.RepTerminationType = -2#
            Result = False
            MinLBFGSIteration = Result
            Exit Function
        End If
        State.Rho(State.p) = 1# / V
        State.GammaK = V / VV
        '
        '  Calculate d(k+1) = -H(k+1)*g(k+1)
        '
        '  for I:=K downto K-Q do
        '      V = s(i)^T * work(iteration:I)
        '      theta(i) = V
        '      work(iteration:I+1) = work(iteration:I) - V*Rho(i)*y(i)
        '  work(last iteration) = H0*work(last iteration)
        '  for I:=K-Q to K do
        '      V = y(i)^T*work(iteration:I)
        '      work(iteration:I+1) = work(iteration:I) +(-V+theta(i))*Rho(i)*s(i)
        '
        '  NOW WORK CONTAINS d(k+1)
        '
        For i_ = 0# To N - 1# Step 1
            State.WORK(i_) = State.G(i_)
        Next i_
        For i = State.K To State.K - State.q Step -1
            IC = i Mod M
            V = 0#
            For i_ = 0# To N - 1# Step 1
                V = V + State.S(IC, i_) * State.WORK(i_)
            Next i_
            State.Theta(IC) = V
            VV = V * State.Rho(IC)
            For i_ = 0# To N - 1# Step 1
                State.WORK(i_) = State.WORK(i_) - VV * State.y(IC, i_)
            Next i_
        Next i
        V = State.GammaK
        For i_ = 0# To N - 1# Step 1
            State.WORK(i_) = V * State.WORK(i_)
        Next i_
        For i = State.K - State.q To State.K Step 1
            IC = i Mod M
            V = 0#
            For i_ = 0# To N - 1# Step 1
                V = V + State.y(IC, i_) * State.WORK(i_)
            Next i_
            VV = State.Rho(IC) * (-V + State.Theta(IC))
            For i_ = 0# To N - 1# Step 1
                State.WORK(i_) = State.WORK(i_) + VV * State.S(IC, i_)
            Next i_
        Next i
        For i_ = 0# To N - 1# Step 1
            State.D(i_) = -State.WORK(i_)
        Next i_
        '
        ' Next step
        '
        State.Fold = State.F
        State.K = State.K + 1#
    End If
    GoTo lbl_6
lbl_7:
    Result = False
    MinLBFGSIteration = Result
    Exit Function
    '
    ' Saving state
    '
lbl_rcomm:
    Result = True
    State.RState.IA(0#) = N
    State.RState.IA(1#) = M
    State.RState.IA(2#) = MaxIts
    State.RState.IA(3#) = i
    State.RState.IA(4#) = j
    State.RState.IA(5#) = IC
    State.RState.IA(6#) = MCINFO
    State.RState.RA(0#) = EpsF
    State.RState.RA(1#) = EpsG
    State.RState.RA(2#) = EpsX
    State.RState.RA(3#) = V
    State.RState.RA(4#) = VV
    MinLBFGSIteration = Result
End Function
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'L-BFGS algorithm results
'
'Called after MinLBFGSIteration() returned False.
'
'INPUT PARAMETERS:
'    State   -   algorithm state (used by MinLBFGSIteration).
'
'OUTPUT PARAMETERS:
'    X       -   array[0..N-1], solution
'    Rep     -   optimization report:
'                * Rep.TerminationType completetion code:
'                    * -2    rounding errors prevent further improvement.
'                            X contains best point found.
'                    * -1    incorrect parameters were specified
'                    *  1    relative function improvement is no more than
'                            EpsF.
'                    *  2    relative step is no more than EpsX.
'                    *  4    gradient norm is no more than EpsG
'                    *  5    MaxIts steps was taken
'                    *  7    stopping conditions are too stringent,
'                            further improvement is impossible
'                * Rep.IterationsCount contains iterations count
'                * NFEV countains number of function calculations
'
'  -- ALGLIB --
'     Copyright 02.04.2010 by Bochkanov Sergey
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Public Sub MinLBFGSResults(ByRef State As MinLBFGSState, _
         ByRef X() As Double, _
         ByRef Rep As MinLBFGSReport)
    Dim i_ As Long
    ReDim X(0# To State.N - 1#)
    For i_ = 0# To State.N - 1# Step 1
        X(i_) = State.X(i_)
    Next i_
    Rep.IterationsCount = State.RepIterationsCount
    Rep.NFEV = State.RepNFEV
    Rep.TerminationType = State.RepTerminationType
End Sub
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'Clears request fileds (to be sure that we don't forgot to clear something)
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
Private Sub ClearRequestFieldsLBFGS(ByRef State As MinLBFGSState)
    State.NeedFG = False
    State.XUpdated = False
End Sub

